{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import scipy.stats\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import statistics\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"LIDC with IH(Mis_fre).csv\")\n",
    "#df = pd.read_csv(\"Copy of LIDC dataset with full annotations.csv\")\n",
    "#medoid = pd.read_csv(\"medoids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>Malignancy_mode</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  \\\n",
       "0           0         1  1094        1286  168.852814       135.372918   \n",
       "1           1         3   931        1062  148.267027       119.799290   \n",
       "2           2         4   161         167   51.455844        49.201081   \n",
       "3           3         5   246         251   58.769553        57.721132   \n",
       "4           4         6    71          73   32.142136        31.494737   \n",
       "\n",
       "   EquivDiameter  MajorAxisLength  MinorAxisLength  Elongation    ...     \\\n",
       "0      37.321898        42.803687        35.834900    1.194469    ...      \n",
       "1      34.429435        39.635819        30.844618    1.285016    ...      \n",
       "2      14.317527        18.125068        11.574663    1.565926    ...      \n",
       "3      17.697936        18.324991        17.321312    1.057945    ...      \n",
       "4       9.507892        10.528352         8.908660    1.181811    ...      \n",
       "\n",
       "   Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  Malignancy3_3  \\\n",
       "0             5             4              3              3              3   \n",
       "1             3             4              3              3              2   \n",
       "2             3             2              3              3              2   \n",
       "3             3             2              3              3              2   \n",
       "4             1             1              1              1              1   \n",
       "\n",
       "   Malignancy3_4  Malignancy3_mode  Propagation  Malignancy_mode        IH  \n",
       "0              3                 3            2                5  0.000000  \n",
       "1              3                 3            2                5  0.000000  \n",
       "2              1                 3            3                4  0.900000  \n",
       "3              1                 3            1                3  0.333333  \n",
       "4              1                 1            3                1  0.533333  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    330\n",
       "2    153\n",
       "1    119\n",
       "4    114\n",
       "5     99\n",
       "Name: Malignancy_mode, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[\"Malignancy_mode\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"noduleID\",'Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4',\n",
    "    \"Malignancy3_1\", 'Malignancy3_2', \"Malignancy3_3\", \"Malignancy3_4\", \"Malignancy3_mode\", \"Propagation\"], axis=1)\n",
    "X = X.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17e5f978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# min_samples_split = 2  min_samples_leaf = 1\n",
    "y_all = df[['Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4']]\n",
    "y_all = y_all.as_matrix()\n",
    "y_allt = np.transpose(y_all)\n",
    "np.random.shuffle(y_allt)\n",
    "y_all = np.transpose(y_allt)\n",
    "y = y_all.T[0]\n",
    "    \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "train_indexs = []\n",
    "test_indexs = []\n",
    "    \n",
    "\n",
    "for train_index, test_index in skf.split(X, y):  \n",
    "    train_indexs.append(train_index)\n",
    "    test_indexs.append(test_index)\n",
    "\n",
    "y_all_train = y_all[train_indexs[0]]\n",
    "y_all_test = y_all[test_indexs[0]]\n",
    "    \n",
    "X_train = X[train_indexs[0]]\n",
    "X_test = X[test_indexs[0]]\n",
    "\n",
    "    \n",
    "##First Iteration\n",
    "\n",
    "y_train1 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "y_test1 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "    \n",
    "#train\n",
    "n = 0\n",
    "for index in train_indexs[0]:\n",
    "    y_train1[n] = y_all[index][0]\n",
    "    n += 1 \n",
    "     \n",
    "#test\n",
    "n = 0\n",
    "for index in test_indexs[0]:\n",
    "    y_test1[n] = y_all[index][0]\n",
    "    n += 1\n",
    "\n",
    "\n",
    "\n",
    "BaggingTestE = []\n",
    "BaggingTrainE = []\n",
    "for numbers_tree in range(1, 50):\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train1_balanced = sm.fit_sample(X_train, y_train1)\n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = 5), n_estimators = numbers_tree, max_samples = 0.632)\n",
    "\n",
    "    cv_results = cross_validate(bagging, X_train_balanced, y_train1_balanced, cv=10, return_train_score=True)\n",
    "    \n",
    "\n",
    "    BaggingTrainE.append(1-cv_results['train_score'].mean())\n",
    "    BaggingTestE.append(1-cv_results['test_score'].mean())\n",
    "    \n",
    "plt.plot(range(1, 50), BaggingTestE)\n",
    "plt.plot(range(1, 50), BaggingTrainE)\n",
    "plt.legend(('Bagging Testing','Bagging Training'))\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xlabel('Number of Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbK0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24bf7240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BaggingTestE = []\n",
    "BaggingTrainE = []\n",
    "for numbers_tree in range(1, 50):\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train1_balanced = sm.fit_sample(X_train, y_train1)\n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = 5, min_samples_split = 10, min_samples_leaf = 5),\n",
    "                                n_estimators = numbers_tree, max_samples = 0.632)\n",
    "\n",
    "    cv_results = cross_validate(bagging, X_train_balanced, y_train1_balanced, cv=10, return_train_score=True)\n",
    "    \n",
    "\n",
    "    BaggingTrainE.append(1-cv_results['train_score'].mean())\n",
    "    BaggingTestE.append(1-cv_results['test_score'].mean())\n",
    "    \n",
    "plt.plot(range(1, 50), BaggingTestE)\n",
    "plt.plot(range(1, 50), BaggingTrainE)\n",
    "plt.legend(('Bagging Testing','Bagging Training'))\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xlabel('Number of Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a172c3b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BaggingTestE = []\n",
    "BaggingTrainE = []\n",
    "for numbers_tree in range(1, 50):\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train1_balanced = sm.fit_sample(X_train, y_train1)\n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = 5, min_samples_split = 20, min_samples_leaf = 10),\n",
    "                                n_estimators = numbers_tree, max_samples = 0.632)\n",
    "\n",
    "    cv_results = cross_validate(bagging, X_train_balanced, y_train1_balanced, cv=10, return_train_score=True)\n",
    "    \n",
    "\n",
    "    BaggingTrainE.append(1-cv_results['train_score'].mean())\n",
    "    BaggingTestE.append(1-cv_results['test_score'].mean())\n",
    "    \n",
    "plt.plot(range(1, 50), BaggingTestE)\n",
    "plt.plot(range(1, 50), BaggingTrainE)\n",
    "plt.legend(('Bagging Testing','Bagging Training'))\n",
    "plt.ylabel('Error Rate')\n",
    "plt.xlabel('Number of Tree')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Instance Hardness (Error Variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#have 20 versions of labels\n",
    "number  = 1\n",
    "\n",
    "train_acc1 = []\n",
    "test_acc1 = []\n",
    "noftree1 = []\n",
    "\n",
    "train_acc2 = []\n",
    "test_acc2 = []\n",
    "noftree2 = []\n",
    "\n",
    "train_acc3 = []\n",
    "test_acc3 = []\n",
    "noftree3 = []\n",
    "\n",
    "train_acc4 = []\n",
    "test_acc4 = []\n",
    "noftree4 = []\n",
    "\n",
    "train_acc1_classes = []\n",
    "train_acc2_classes = []\n",
    "train_acc3_classes = []\n",
    "train_acc4_classes = []\n",
    "\n",
    "train_sen1_classes = []\n",
    "train_sen2_classes = []\n",
    "train_sen3_classes = []\n",
    "train_sen4_classes = []\n",
    "\n",
    "train_spe1_classes = []\n",
    "train_spe2_classes = []\n",
    "train_spe3_classes = []\n",
    "train_spe4_classes = []\n",
    "\n",
    "test_acc1_classes = []\n",
    "test_acc2_classes = []\n",
    "test_acc3_classes = []\n",
    "test_acc4_classes = []\n",
    "\n",
    "test_sen1_classes = []\n",
    "test_sen2_classes = []\n",
    "test_sen3_classes = []\n",
    "test_sen4_classes = []\n",
    "\n",
    "test_spe1_classes = []\n",
    "test_spe2_classes = []\n",
    "test_spe3_classes = []\n",
    "test_spe4_classes = []\n",
    "  \n",
    "\n",
    "depth = 5\n",
    "noftree_s = 20\n",
    "noftree_e = 40\n",
    "noftree_n = noftree_e - noftree_s\n",
    "\n",
    "\n",
    "cost1 = []\n",
    "cost2 = []\n",
    "cost3 = []\n",
    "cost4 = []\n",
    "\n",
    "all_variance = {}\n",
    "for index in df.index:\n",
    "    all_variance[index] = 0\n",
    "\n",
    "while number <= 20 :\n",
    "    number += 1\n",
    "    \n",
    "    y_all = df[['Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4']]\n",
    "    y_all = y_all.as_matrix()\n",
    "    y_allt = np.transpose(y_all)\n",
    "    np.random.shuffle(y_allt)\n",
    "    y_all = np.transpose(y_allt)\n",
    "    y = y_all.T[0]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "    train_indexs = []\n",
    "    test_indexs = []\n",
    "    \n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):  \n",
    "        train_indexs.append(train_index)\n",
    "        test_indexs.append(test_index)\n",
    "    \n",
    "    X_train = X[train_indexs[0]]\n",
    "    X_test = X[test_indexs[0]]\n",
    "    \n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #min_max_scaler.fit(X_train)\n",
    "    #X_train = min_max_scaler.fit_transform(X_train)\n",
    "    #X_test = min_max_scaler.fit_transform(X_test)\n",
    "    \n",
    "    y_all_train = y_all[train_indexs[0]]\n",
    "    y_all_test = y_all[test_indexs[0]]\n",
    "    \n",
    "    ##First Iteration\n",
    "\n",
    "    y_train1 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test1 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "    \n",
    "    #train\n",
    "    n = 0\n",
    "    for index in train_indexs[0]:\n",
    "        y_train1[n] = y_all[index][0]\n",
    "        n += 1 \n",
    "     \n",
    "    #test\n",
    "    n = 0\n",
    "    for index in test_indexs[0]:\n",
    "        y_test1[n] = y_all[index][0]\n",
    "        n += 1\n",
    "        \n",
    "    #Predction\n",
    "    #Balance\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train1_balanced = sm.fit_sample(X_train, y_train1)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train1_balanced)\n",
    "    noftree1.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_1 = []\n",
    "    mis_test_1 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train1_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc1.append(accuracy_score(y_train1, bagging_train_pred))\n",
    "    test_acc1.append(accuracy_score(y_test1, bagging_test_pred))\n",
    "    \n",
    "    #train\n",
    "    cm = confusion_matrix(y_train1, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc1_classes.append(train_acc_class)\n",
    "    train_sen1_classes.append(train_sen_class)\n",
    "    train_spe1_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test1, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc1_classes.append(test_acc_class)\n",
    "    test_sen1_classes.append(test_sen_class)\n",
    "    test_spe1_classes.append(test_spe_class)  \n",
    "\n",
    "    #calculate errors\n",
    "    mis_train_error_1 = abs(y_train1 - bagging_train_pred)\n",
    "    mis_test_error_1 = abs(y_test1 - bagging_test_pred)\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_1, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_1.append(j) \n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_1, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_1.append(j)\n",
    "\n",
    "    cost1.append(len(mis_train_1)+len(mis_test_1))\n",
    "    \n",
    "    ##Second Iteration\n",
    "    \n",
    "    #Update labels\n",
    "    \n",
    "    y_train2 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test2 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "\n",
    "    #train\n",
    "    n = 0\n",
    "    for a, b in zip(mis_train_error_1, y_all_train):                                \n",
    "        if a != 0:\n",
    "            y_train2[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_train2[n] = y_train1[n]\n",
    "        n += 1   \n",
    "    \n",
    "    #test\n",
    "    n = 0\n",
    "    for a, b in zip(mis_test_error_1, y_all_test):                                \n",
    "        if a != 0:\n",
    "            y_test2[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_test2[n] = y_test1[n]\n",
    "        n += 1           \n",
    "    \n",
    "    \n",
    "    #Predction\n",
    "    #Balanced\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train2_balanced = sm.fit_sample(X_train, y_train2)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train2_balanced)\n",
    "    noftree2.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_2 = []\n",
    "    mis_test_2 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train2_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc2.append(accuracy_score(y_train2, bagging_train_pred))\n",
    "    test_acc2.append(accuracy_score(y_test2, bagging_test_pred))\n",
    "    \n",
    "    #train\n",
    "    cm = confusion_matrix(y_train2, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc2_classes.append(train_acc_class)\n",
    "    train_sen2_classes.append(train_sen_class)\n",
    "    train_spe2_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test2, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc2_classes.append(test_acc_class)\n",
    "    test_sen2_classes.append(test_sen_class)\n",
    "    test_spe2_classes.append(test_spe_class)  \n",
    "    \n",
    "    #calculate errors\n",
    "    mis_train_error_2 = abs(y_train2 - bagging_train_pred)\n",
    "    mis_test_error_2 = abs(y_test2 - bagging_test_pred)\n",
    "    \n",
    "    c = 0\n",
    "    for i, j in zip(mis_train_error_2, train_indexs[0]):\n",
    "        if j not in mis_train_1:\n",
    "            mis_train_error_2[c] = 0\n",
    "            mis_train_error_1[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    c = 0\n",
    "    for i, j in zip(mis_test_error_2, test_indexs[0]):\n",
    "        if j not in mis_test_1:\n",
    "            mis_test_error_2[c] = 0\n",
    "            mis_test_error_1[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_2, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_2.append(j)\n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_2, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_2.append(j)\n",
    "\n",
    "    cost2.append(len(mis_train_2)+len(mis_test_2))\n",
    "        \n",
    "    ##Third Iteration\n",
    "    \n",
    "    #Update labels\n",
    "    \n",
    "    y_train3 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test3 = np.zeros(y[test_indexs[0]].shape[0])  \n",
    "  \n",
    "    #train\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_train_error_2, y_all_train, train_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #3 labels\n",
    "            if c in mis_train_1 and c in mis_train_2:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train3[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_train3[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            #2 labels\n",
    "            else:\n",
    "                y_train3[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_train3[n] = y_train2[n]\n",
    "        n += 1  \n",
    "    \n",
    "    #test\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_test_error_2, y_all_test, test_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #3 labels\n",
    "            if c in mis_test_1 and c in mis_test_2:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test3[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_test3[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            #2 labels\n",
    "            else:\n",
    "                y_test3[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_test3[n] = y_test2[n]\n",
    "        n += 1\n",
    "    \n",
    "    \n",
    "    #Prediction\n",
    "    #Balanced\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train3_balanced = sm.fit_sample(X_train, y_train3)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train3_balanced)\n",
    "    noftree3.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_3 = []\n",
    "    mis_test_3 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train3_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc3.append(accuracy_score(y_train3, bagging_train_pred))\n",
    "    test_acc3.append(accuracy_score(y_test3, bagging_test_pred))\n",
    "\n",
    "    #train\n",
    "    cm = confusion_matrix(y_train3, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc3_classes.append(train_acc_class)\n",
    "    train_sen3_classes.append(train_sen_class)\n",
    "    train_spe3_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test3, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc3_classes.append(test_acc_class)\n",
    "    test_sen3_classes.append(test_sen_class)\n",
    "    test_spe3_classes.append(test_spe_class)  \n",
    "    \n",
    "    #calculate errors\n",
    "    mis_train_error_3 = abs(y_train3 - bagging_train_pred)\n",
    "    mis_test_error_3 = abs(y_test3 - bagging_test_pred)\n",
    "    \n",
    "    c = 0\n",
    "    for i, j in zip(mis_train_error_3, train_indexs[0]):\n",
    "        if j not in mis_train_1 and j not in mis_train_2:\n",
    "            mis_train_error_3[c] = 0\n",
    "            mis_train_error_1[c] = i\n",
    "        elif j not in mis_train_1 and j in mis_train_2:\n",
    "            mis_train_error_3[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j in mis_train_1 and j not in mis_train_2:\n",
    "            mis_train_error_3[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    c = 0\n",
    "    for i, j in zip(mis_test_error_3, test_indexs[0]):\n",
    "        if j not in mis_test_1 and j not in mis_test_2:\n",
    "            mis_test_error_3[c] = 0\n",
    "            mis_test_error_1[c] = i\n",
    "        elif j not in mis_test_1 and j in mis_test_2:\n",
    "            mis_test_error_3[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j in mis_test_1 and j not in mis_test_2:\n",
    "            mis_test_error_3[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_3, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_3.append(j)\n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_3, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_3.append(j)\n",
    "\n",
    "    cost3.append(len(mis_train_3)+len(mis_test_3))\n",
    "\n",
    "    ##Fourth Iteration\n",
    "    \n",
    "    #Update labels\n",
    "   \n",
    "    y_train4 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test4 = np.zeros(y[test_indexs[0]].shape[0])  \n",
    "\n",
    "    #train\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_train_error_3, y_all_train, train_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #4 labels\n",
    "            if c in mis_train_1 and c in mis_train_2 and c in mis_train_3:\n",
    "                if b[3] == b[0] and b[1] == b[2]:    \n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[1] and b[0] == b[2]:    \n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[2] and b[0] == b[1]:    \n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                else:\n",
    "                    y_train4[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "            \n",
    "            # 3 labels\n",
    "            elif c in mis_train_1 and c in mis_train_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_train4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            \n",
    "                \n",
    "            #3 labels\n",
    "            elif c in mis_train_2 and c in mis_train_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_train4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "\n",
    "            \n",
    "            #2 labels\n",
    "            else:\n",
    "                y_train4[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_train4[n] = y_train3[n]\n",
    "        \n",
    "        n += 1  \n",
    "\n",
    "    \n",
    "    #test\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_test_error_3, y_all_test, test_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #4 labels\n",
    "            if c in mis_test_1 and c in mis_test_2 and c in mis_test_3:\n",
    "                if b[3] == b[0] and b[1] == b[2]:    \n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[1] and b[0] == b[2]:    \n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[2] and b[0] == b[1]:    \n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                else:\n",
    "                    y_test4[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "\n",
    "            # 3 labels\n",
    "            elif c in mis_test_1 and c in mis_test_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_test4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            \n",
    "                \n",
    "            #3 labels\n",
    "            elif c in mis_test_2 and c in mis_test_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_test4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            \n",
    "            #2 labels\n",
    "            else:\n",
    "                y_test4[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_test4[n] = y_test3[n]\n",
    "        \n",
    "        n += 1  \n",
    "   \n",
    "    #Prediction\n",
    "    #Balanced\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train4_balanced = sm.fit_sample(X_train, y_train4)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train4_balanced)\n",
    "    noftree4.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_4 = []\n",
    "    mis_test_4 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train4_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc4.append(accuracy_score(y_train4, bagging_train_pred))\n",
    "    test_acc4.append(accuracy_score(y_test4, bagging_test_pred))\n",
    "\n",
    "    #train\n",
    "    cm = confusion_matrix(y_train4, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc4_classes.append(train_acc_class)\n",
    "    train_sen4_classes.append(train_sen_class)\n",
    "    train_spe4_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test4, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc4_classes.append(test_acc_class)\n",
    "    test_sen4_classes.append(test_sen_class)\n",
    "    test_spe4_classes.append(test_spe_class)  \n",
    "    \n",
    "    #calculate errors\n",
    "    mis_train_error_4 = abs(y_train4 - bagging_train_pred)\n",
    "    mis_test_error_4 = abs(y_test4 - bagging_test_pred)\n",
    "    \n",
    "    c = 0\n",
    "    for i, j in zip(mis_train_error_4, train_indexs[0]):\n",
    "        if j not in mis_train_1 and j not in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_1[c] = i\n",
    "        elif j in mis_train_1 and j not in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j not in mis_train_1 and j in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j not in mis_train_1 and j not in mis_train_2 and j in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j in mis_train_1 and j in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j not in mis_train_1 and j in mis_train_2 and j in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j in mis_train_1 and j not in mis_train_2 and j in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        c += 1\n",
    "     \n",
    "    c = 0\n",
    "    for i, j in zip(mis_test_error_4, test_indexs[0]):\n",
    "        if j not in mis_test_1 and j not in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_1[c] = i\n",
    "        elif j in mis_test_1 and j not in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j not in mis_test_1 and j in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j not in mis_test_1 and j not in mis_test_2 and j in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j in mis_test_1 and j in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j not in mis_test_1 and j in mis_test_2 and j in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j in mis_test_1 and j not in mis_test_2 and j in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_4, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_4.append(j)\n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_4, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_4.append(j)\n",
    "        \n",
    "    cost4.append(len(mis_train_4)+len(mis_test_4))  \n",
    "    \n",
    "    #Weighted Errors Variance\n",
    "    variance_train = {}\n",
    "    for index, one, two, three, four in zip(train_indexs[0], mis_train_error_1, mis_train_error_2, mis_train_error_3, mis_train_error_4):\n",
    "        wmean = one * (1/10) + two * (2/10) + three * (3/10) + four * (4/10)\n",
    "        variance_train[index] = (1/10)*(one-wmean)**2+(2/10)*(two-wmean)**2+(3/10)*(three-wmean)**2+(4/10)*(four-wmean)**2\n",
    "        \n",
    "    variance_test = {}\n",
    "    for index, one, two, three, four in zip(test_indexs[0], mis_test_error_1, mis_test_error_2, mis_test_error_3, mis_test_error_4):\n",
    "        wmean = one * (1/10) + two * (2/10) + three * (3/10) + four * (4/10)\n",
    "        variance_test[index] = (1/10)*(one-wmean)**2+(2/10)*(two-wmean)**2+(3/10)*(three-wmean)**2+(4/10)*(four-wmean)**2\n",
    "\n",
    "    for key, value in variance_train.items():\n",
    "        all_variance[key] = all_variance[key] + value\n",
    "        \n",
    "    for key, value in variance_test.items():\n",
    "        all_variance[key] = all_variance[key] + value\n",
    "        \n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Hardness Instance (Misclassification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ratings = df[[\"Malignancy_1\",'Malignancy_2','Malignancy_3', \"Malignancy_4\"]].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Malignancy_mode = np.zeros(all_ratings.shape[0])  \n",
    "\n",
    "n = 0\n",
    "for b in all_ratings:                                \n",
    "    if b[3] == b[0] and b[1] == b[2]:    \n",
    "        Malignancy_mode[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "    elif b[3] == b[1] and b[0] == b[2]:    \n",
    "        Malignancy_mode[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "    elif b[3] == b[2] and b[0] == b[1]:    \n",
    "        Malignancy_mode[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "    elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "        Malignancy_mode[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "    else:\n",
    "        Malignancy_mode[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Malignancy_mode = Malignancy_mode.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop([\"IH\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>Malignancy_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness       ...         \\\n",
       "0        42.803687        35.834900    1.194469     2.073908       ...          \n",
       "1        39.635819        30.844618    1.285016     1.879012       ...          \n",
       "2        18.125068        11.574663    1.565926     1.308681       ...          \n",
       "3        18.324991        17.321312    1.057945     1.117274       ...          \n",
       "4        10.528352         8.908660    1.181811     1.157927       ...          \n",
       "\n",
       "   Malignancy_2  Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  \\\n",
       "0             5             5             4              3              3   \n",
       "1             5             3             4              3              3   \n",
       "2             4             3             2              3              3   \n",
       "3             5             3             2              3              3   \n",
       "4             1             1             1              1              1   \n",
       "\n",
       "   Malignancy3_3  Malignancy3_4  Malignancy3_mode  Propagation  \\\n",
       "0              3              3                 3            2   \n",
       "1              2              3                 3            2   \n",
       "2              2              1                 3            3   \n",
       "3              2              1                 3            1   \n",
       "4              1              1                 1            3   \n",
       "\n",
       "   Malignancy_mode  \n",
       "0                5  \n",
       "1                5  \n",
       "2                4  \n",
       "3                3  \n",
       "4                1  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Malignancy_mode\"] = Malignancy_mode\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"noduleID\",'Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4',\n",
    "    \"Malignancy3_1\", 'Malignancy3_2', \"Malignancy3_3\", \"Malignancy3_4\", \"Malignancy3_mode\", \"Propagation\", \"Malignancy_mode\"], axis=1)\n",
    "X = X.as_matrix()\n",
    "y = Malignancy_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Create module for concrete IH calculation so that it can be used by other programs\n",
    "def calculate_concrete_IH(X, y, full, clfList):\n",
    "    ndata = X.shape[0]\n",
    "    numClf = len(clfList) # Num of classifiers\n",
    "    knn_clf = KNeighborsClassifier(int(np.floor(np.sqrt(ndata)/2))) # k = sqrt(n)/2\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=5) \n",
    "    nb_clf = GaussianNB()\n",
    "    lr_clf = LogisticRegression()\n",
    "    lda_clf = LinearDiscriminantAnalysis()\n",
    "    qda_clf = QuadraticDiscriminantAnalysis()\n",
    "    \n",
    "\n",
    "    # Matrix that record misclassification\n",
    "    misclf_matrix = np.zeros((ndata, numClf))\n",
    "\n",
    "    # If full = True, perform Leave-one-out cross validation for all classifiers\n",
    "    if full == True:\n",
    "        loo = LeaveOneOut()\n",
    "        for train_index, test_index in loo.split(X):\n",
    "    \n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            # Classifier 0: kNN\n",
    "            if 0 in clfList:\n",
    "                knn_clf.fit(X_train, y_train)\n",
    "                pred_knn = knn_clf.predict(X_test)\n",
    "                if pred_knn != y_test:\n",
    "                    misclf_matrix[test_index[0]][0] = 1\n",
    "                             \n",
    "            # Classifier 1: Decision Tree\n",
    "            if 1 in clfList:             \n",
    "                tree_clf.fit(X_train, y_train)\n",
    "                pred_tree = tree_clf.predict(X_test)\n",
    "                if pred_tree != y_test:\n",
    "                    misclf_matrix[test_index[0]][1] = 1\n",
    "                                                  \n",
    "            # Classifier 2: Naive Bayes                 \n",
    "            if 2 in clfList:\n",
    "                nb_clf.fit(X_train, y_train)\n",
    "                pred_nb = nb_clf.predict(X_test)\n",
    "                if pred_nb != y_test:\n",
    "                    misclf_matrix[test_index[0]][2] = 1\n",
    "                                                               \n",
    "            # Classifier 3: Logistic Regression\n",
    "            if 3 in clfList:                 \n",
    "                lr_clf.fit(X_train, y_train)\n",
    "                pred_lr = lr_clf.predict(X_test)\n",
    "                if pred_lr != y_test:\n",
    "                    misclf_matrix[test_index[0]][3] = 1\n",
    "                         \n",
    "            # Classifier 4: LDA\n",
    "            if 4 in clfList:\n",
    "                lda_clf.fit(X_train, y_train)\n",
    "                pred_lda = lda_clf.predict(X_test)\n",
    "                if pred_lda != y_test:\n",
    "                    misclf_matrix[test_index[0]][4] = 1\n",
    "            \n",
    "            # Classifier 5: QDA\n",
    "            if 5 in clfList:\n",
    "                qda_clf.fit(X_train, y_train)\n",
    "                pred_qda = qda_clf.predict(X_test)\n",
    "                if pred_qda != y_test:\n",
    "                    misclf_matrix[test_index[0]][5] = 1\n",
    "            \n",
    "            ih_vector = np.zeros(ndata)\n",
    "            for i in range(ndata):\n",
    "                ih_vector[i] = sum(misclf_matrix[i,:])/numClf\n",
    "                         \n",
    "        return ih_vector, misclf_matrix  \n",
    "    \n",
    "    # else perform niter by nfolds (default is 5 by 10) fold cross validation\n",
    "    else:\n",
    "        niter = 5   # Num of iterations\n",
    "        nfolds = 10      \n",
    "        misclf = np.zeros((ndata, numClf, niter))  # For each data, misclassif by each classifier on each iteration\n",
    "        \n",
    "        for randseed in range(niter):\n",
    "            np.random.seed(randseed)\n",
    "            kf = KFold(n_splits=nfolds, shuffle=True)\n",
    "            fold = 0\n",
    "            for tr_idx, test_idx in kf.split(X):\n",
    "\n",
    "                X_train, X_test = X[tr_idx], X[test_idx]\n",
    "                y_train, y_test = y[tr_idx], y[test_idx] \n",
    "                \n",
    "                # Classifier 0: kNN\n",
    "                if 0 in clfList:\n",
    "                    knn_clf.fit(X_train, y_train)\n",
    "                    pred_knn = knn_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_knn[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][0][randseed] = 1\n",
    "                                 \n",
    "                # Classifier 1: Decision Tree \n",
    "                if 1 in clfList:\n",
    "                    tree_clf.fit(X_train, y_train)\n",
    "                    pred_tree = tree_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_tree[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][1][randseed] = 1\n",
    "    \n",
    "                                                  \n",
    "                # Classifier 2: Naive Bayes  \n",
    "                if 2 in clfList:\n",
    "                    nb_clf.fit(X_train, y_train)\n",
    "                    pred_nb = nb_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_nb[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][2][randseed] = 1\n",
    "            \n",
    "                # Classifier 3: Logistic Regression \n",
    "                if 3 in clfList:                \n",
    "                    lr_clf.fit(X_train, y_train)\n",
    "                    pred_lr = lr_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_lr[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][3][randseed] = 1\n",
    "    \n",
    "                             \n",
    "                # Classifier 4: LDA\n",
    "                if 4 in clfList:\n",
    "                    lda_clf.fit(X_train, y_train)\n",
    "                    pred_lda = lda_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_lda[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][4][randseed] = 1\n",
    "    \n",
    "                \n",
    "                # Classifier 5: QDA\n",
    "                if 5 in clfList:\n",
    "                    qda_clf.fit(X_train, y_train)\n",
    "                    pred_qda = qda_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_qda[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][5][randseed] = 1\n",
    "                            \n",
    "                # Classifier 6: SVM\n",
    "                if 5 in clfList:\n",
    "                    qda_clf.fit(X_train, y_train)\n",
    "                    pred_qda = qda_clf.predict(X_test)\n",
    "                    for i in range(len(test_idx)):\n",
    "                        if pred_qda[i] != y_test[i]:\n",
    "                            misclf[test_idx[i]][5][randseed] = 1\n",
    "                \n",
    "                fold = fold + 1\n",
    "\n",
    "        ih_vector = np.zeros(ndata)\n",
    "        for i in range(ndata):\n",
    "            ih_vector[i] = sum(sum(misclf[i]))/(numClf*niter)   # Avg of matrix with numClf classifiers and niter iterations\n",
    "        \n",
    "        return ih_vector, misclf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit(X)\n",
    "X_norm = min_max_scaler.fit_transform(X)\n",
    "\n",
    "ih_vector, misclf = calculate_concrete_IH(X_norm, y, False, range(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 124.,   67.,  104.,   65.,   72.,   79.,   68.,   26.,   67.,  143.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMYZ9JLUOINekhpn0EtS4/4Ph7wdNMZ+SPkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0e98d128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"IH_mis_fre\"] = ih_vector\n",
    "plt.hist(df[\"IH_mis_fre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of Hardness Instance (Mean Squared Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "#have 20 versions of labels\n",
    "number  = 1\n",
    "\n",
    "train_acc1 = []\n",
    "test_acc1 = []\n",
    "noftree1 = []\n",
    "\n",
    "train_acc2 = []\n",
    "test_acc2 = []\n",
    "noftree2 = []\n",
    "\n",
    "train_acc3 = []\n",
    "test_acc3 = []\n",
    "noftree3 = []\n",
    "\n",
    "train_acc4 = []\n",
    "test_acc4 = []\n",
    "noftree4 = []\n",
    "\n",
    "train_acc1_classes = []\n",
    "train_acc2_classes = []\n",
    "train_acc3_classes = []\n",
    "train_acc4_classes = []\n",
    "\n",
    "train_sen1_classes = []\n",
    "train_sen2_classes = []\n",
    "train_sen3_classes = []\n",
    "train_sen4_classes = []\n",
    "\n",
    "train_spe1_classes = []\n",
    "train_spe2_classes = []\n",
    "train_spe3_classes = []\n",
    "train_spe4_classes = []\n",
    "\n",
    "test_acc1_classes = []\n",
    "test_acc2_classes = []\n",
    "test_acc3_classes = []\n",
    "test_acc4_classes = []\n",
    "\n",
    "test_sen1_classes = []\n",
    "test_sen2_classes = []\n",
    "test_sen3_classes = []\n",
    "test_sen4_classes = []\n",
    "\n",
    "test_spe1_classes = []\n",
    "test_spe2_classes = []\n",
    "test_spe3_classes = []\n",
    "test_spe4_classes = []\n",
    "  \n",
    "\n",
    "depth = 5\n",
    "noftree_s = 20\n",
    "noftree_e = 40\n",
    "noftree_n = noftree_e - noftree_s\n",
    "\n",
    "\n",
    "cost1 = []\n",
    "cost2 = []\n",
    "cost3 = []\n",
    "cost4 = []\n",
    "\n",
    "all_variance = {}\n",
    "for index in df.index:\n",
    "    all_variance[index] = 0\n",
    "\n",
    "while number <= 20 :\n",
    "    number += 1\n",
    "    \n",
    "    y_all = df[['Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4']]\n",
    "    y_all = y_all.as_matrix()\n",
    "    y_allt = np.transpose(y_all)\n",
    "    np.random.shuffle(y_allt)\n",
    "    y_all = np.transpose(y_allt)\n",
    "    y = y_all.T[0]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "    train_indexs = []\n",
    "    test_indexs = []\n",
    "    \n",
    "\n",
    "    for train_index, test_index in skf.split(X, y):  \n",
    "        train_indexs.append(train_index)\n",
    "        test_indexs.append(test_index)\n",
    "    \n",
    "    X_train = X[train_indexs[0]]\n",
    "    X_test = X[test_indexs[0]]\n",
    "    \n",
    "    #min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    #min_max_scaler.fit(X_train)\n",
    "    #X_train = min_max_scaler.fit_transform(X_train)\n",
    "    #X_test = min_max_scaler.fit_transform(X_test)\n",
    "    \n",
    "    y_all_train = y_all[train_indexs[0]]\n",
    "    y_all_test = y_all[test_indexs[0]]\n",
    "    \n",
    "    ##First Iteration\n",
    "\n",
    "    y_train1 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test1 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "    \n",
    "    #train\n",
    "    n = 0\n",
    "    for index in train_indexs[0]:\n",
    "        y_train1[n] = y_all[index][0]\n",
    "        n += 1 \n",
    "     \n",
    "    #test\n",
    "    n = 0\n",
    "    for index in test_indexs[0]:\n",
    "        y_test1[n] = y_all[index][0]\n",
    "        n += 1\n",
    "        \n",
    "    #Predction\n",
    "    #Balance\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train1_balanced = sm.fit_sample(X_train, y_train1)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train1_balanced)\n",
    "    noftree1.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_1 = []\n",
    "    mis_test_1 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train1_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc1.append(accuracy_score(y_train1, bagging_train_pred))\n",
    "    test_acc1.append(accuracy_score(y_test1, bagging_test_pred))\n",
    "    \n",
    "    #train\n",
    "    cm = confusion_matrix(y_train1, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc1_classes.append(train_acc_class)\n",
    "    train_sen1_classes.append(train_sen_class)\n",
    "    train_spe1_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test1, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc1_classes.append(test_acc_class)\n",
    "    test_sen1_classes.append(test_sen_class)\n",
    "    test_spe1_classes.append(test_spe_class)  \n",
    "\n",
    "    #calculate errors\n",
    "    mis_train_error_1 = abs(y_train1 - bagging_train_pred)\n",
    "    mis_test_error_1 = abs(y_test1 - bagging_test_pred)\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_1, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_1.append(j) \n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_1, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_1.append(j)\n",
    "\n",
    "    cost1.append(len(mis_train_1)+len(mis_test_1))\n",
    "    \n",
    "    ##Second Iteration\n",
    "    \n",
    "    #Update labels\n",
    "    \n",
    "    y_train2 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test2 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "\n",
    "    #train\n",
    "    n = 0\n",
    "    for a, b in zip(mis_train_error_1, y_all_train):                                \n",
    "        if a != 0:\n",
    "            y_train2[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_train2[n] = y_train1[n]\n",
    "        n += 1   \n",
    "    \n",
    "    #test\n",
    "    n = 0\n",
    "    for a, b in zip(mis_test_error_1, y_all_test):                                \n",
    "        if a != 0:\n",
    "            y_test2[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_test2[n] = y_test1[n]\n",
    "        n += 1           \n",
    "    \n",
    "    \n",
    "    #Predction\n",
    "    #Balanced\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train2_balanced = sm.fit_sample(X_train, y_train2)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train2_balanced)\n",
    "    noftree2.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_2 = []\n",
    "    mis_test_2 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train2_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc2.append(accuracy_score(y_train2, bagging_train_pred))\n",
    "    test_acc2.append(accuracy_score(y_test2, bagging_test_pred))\n",
    "    \n",
    "    #train\n",
    "    cm = confusion_matrix(y_train2, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc2_classes.append(train_acc_class)\n",
    "    train_sen2_classes.append(train_sen_class)\n",
    "    train_spe2_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test2, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc2_classes.append(test_acc_class)\n",
    "    test_sen2_classes.append(test_sen_class)\n",
    "    test_spe2_classes.append(test_spe_class)  \n",
    "    \n",
    "    #calculate errors\n",
    "    mis_train_error_2 = abs(y_train2 - bagging_train_pred)\n",
    "    mis_test_error_2 = abs(y_test2 - bagging_test_pred)\n",
    "    \n",
    "    c = 0\n",
    "    for i, j in zip(mis_train_error_2, train_indexs[0]):\n",
    "        if j not in mis_train_1:\n",
    "            mis_train_error_2[c] = 0\n",
    "            mis_train_error_1[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    c = 0\n",
    "    for i, j in zip(mis_test_error_2, test_indexs[0]):\n",
    "        if j not in mis_test_1:\n",
    "            mis_test_error_2[c] = 0\n",
    "            mis_test_error_1[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_2, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_2.append(j)\n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_2, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_2.append(j)\n",
    "\n",
    "    cost2.append(len(mis_train_2)+len(mis_test_2))\n",
    "        \n",
    "    ##Third Iteration\n",
    "    \n",
    "    #Update labels\n",
    "    \n",
    "    y_train3 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test3 = np.zeros(y[test_indexs[0]].shape[0])  \n",
    "  \n",
    "    #train\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_train_error_2, y_all_train, train_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #3 labels\n",
    "            if c in mis_train_1 and c in mis_train_2:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train3[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_train3[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            #2 labels\n",
    "            else:\n",
    "                y_train3[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_train3[n] = y_train2[n]\n",
    "        n += 1  \n",
    "    \n",
    "    #test\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_test_error_2, y_all_test, test_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #3 labels\n",
    "            if c in mis_test_1 and c in mis_test_2:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test3[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_test3[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            #2 labels\n",
    "            else:\n",
    "                y_test3[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_test3[n] = y_test2[n]\n",
    "        n += 1\n",
    "    \n",
    "    \n",
    "    #Prediction\n",
    "    #Balanced\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train3_balanced = sm.fit_sample(X_train, y_train3)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train3_balanced)\n",
    "    noftree3.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_3 = []\n",
    "    mis_test_3 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train3_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc3.append(accuracy_score(y_train3, bagging_train_pred))\n",
    "    test_acc3.append(accuracy_score(y_test3, bagging_test_pred))\n",
    "\n",
    "    #train\n",
    "    cm = confusion_matrix(y_train3, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc3_classes.append(train_acc_class)\n",
    "    train_sen3_classes.append(train_sen_class)\n",
    "    train_spe3_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test3, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc3_classes.append(test_acc_class)\n",
    "    test_sen3_classes.append(test_sen_class)\n",
    "    test_spe3_classes.append(test_spe_class)  \n",
    "    \n",
    "    #calculate errors\n",
    "    mis_train_error_3 = abs(y_train3 - bagging_train_pred)\n",
    "    mis_test_error_3 = abs(y_test3 - bagging_test_pred)\n",
    "    \n",
    "    c = 0\n",
    "    for i, j in zip(mis_train_error_3, train_indexs[0]):\n",
    "        if j not in mis_train_1 and j not in mis_train_2:\n",
    "            mis_train_error_3[c] = 0\n",
    "            mis_train_error_1[c] = i\n",
    "        elif j not in mis_train_1 and j in mis_train_2:\n",
    "            mis_train_error_3[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j in mis_train_1 and j not in mis_train_2:\n",
    "            mis_train_error_3[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    c = 0\n",
    "    for i, j in zip(mis_test_error_3, test_indexs[0]):\n",
    "        if j not in mis_test_1 and j not in mis_test_2:\n",
    "            mis_test_error_3[c] = 0\n",
    "            mis_test_error_1[c] = i\n",
    "        elif j not in mis_test_1 and j in mis_test_2:\n",
    "            mis_test_error_3[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j in mis_test_1 and j not in mis_test_2:\n",
    "            mis_test_error_3[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_3, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_3.append(j)\n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_3, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_3.append(j)\n",
    "\n",
    "    cost3.append(len(mis_train_3)+len(mis_test_3))\n",
    "\n",
    "    ##Fourth Iteration\n",
    "    \n",
    "    #Update labels\n",
    "   \n",
    "    y_train4 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "    y_test4 = np.zeros(y[test_indexs[0]].shape[0])  \n",
    "\n",
    "    #train\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_train_error_3, y_all_train, train_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #4 labels\n",
    "            if c in mis_train_1 and c in mis_train_2 and c in mis_train_3:\n",
    "                if b[3] == b[0] and b[1] == b[2]:    \n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[1] and b[0] == b[2]:    \n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[2] and b[0] == b[1]:    \n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                else:\n",
    "                    y_train4[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "            \n",
    "            # 3 labels\n",
    "            elif c in mis_train_1 and c in mis_train_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_train4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            \n",
    "                \n",
    "            #3 labels\n",
    "            elif c in mis_train_2 and c in mis_train_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_train4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_train4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "\n",
    "            \n",
    "            #2 labels\n",
    "            else:\n",
    "                y_train4[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_train4[n] = y_train3[n]\n",
    "        \n",
    "        n += 1  \n",
    "\n",
    "    \n",
    "    #test\n",
    "    n = 0\n",
    "    for a, b, c in zip(mis_test_error_3, y_all_test, test_indexs[0]):                                \n",
    "        if a != 0:\n",
    "            #4 labels\n",
    "            if c in mis_test_1 and c in mis_test_2 and c in mis_test_3:\n",
    "                if b[3] == b[0] and b[1] == b[2]:    \n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[1] and b[0] == b[2]:    \n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] == b[2] and b[0] == b[1]:    \n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                else:\n",
    "                    y_test4[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "\n",
    "            # 3 labels\n",
    "            elif c in mis_test_1 and c in mis_test_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_test4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            \n",
    "                \n",
    "            #3 labels\n",
    "            elif c in mis_test_2 and c in mis_test_3:\n",
    "                if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                    y_test4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                else:\n",
    "                    y_test4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "            \n",
    "            #2 labels\n",
    "            else:\n",
    "                y_test4[n] = int((b[0] + b[1])/2)\n",
    "        else:\n",
    "            y_test4[n] = y_test3[n]\n",
    "        \n",
    "        n += 1  \n",
    "   \n",
    "    #Prediction\n",
    "    #Balanced\n",
    "    sm = SMOTE(random_state=2)\n",
    "    X_train_balanced, y_train4_balanced = sm.fit_sample(X_train, y_train4)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632)\n",
    "    \n",
    "    parameters = {\n",
    "        'n_estimators': np.array([int(e) for e in np.linspace(noftree_s,noftree_e,noftree_n)]),\n",
    "    }\n",
    "    gs = GridSearchCV(bagging, parameters, cv=10)\n",
    "    gs.fit(X_train_balanced, y_train4_balanced)\n",
    "    noftree4.append(gs.best_params_)\n",
    "    \n",
    "    bagging = BaggingClassifier(DecisionTreeClassifier(max_depth = depth), max_samples = 0.632, n_estimators = gs.best_params_[\"n_estimators\"])\n",
    "    \n",
    "    mis_train_4 = []\n",
    "    mis_test_4 = []\n",
    "    \n",
    "    bagging.fit(X_train_balanced,y_train4_balanced)\n",
    "    bagging_train_pred = bagging.predict(X_train)\n",
    "    bagging_test_pred = bagging.predict(X_test)\n",
    "    train_acc4.append(accuracy_score(y_train4, bagging_train_pred))\n",
    "    test_acc4.append(accuracy_score(y_test4, bagging_test_pred))\n",
    "\n",
    "    #train\n",
    "    cm = confusion_matrix(y_train4, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "    train_acc_class = []\n",
    "    train_sen_class = []\n",
    "    train_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        train_acc_class.append(accuracy)\n",
    "        train_sen_class.append(sensitivity)\n",
    "        train_spe_class.append(specificity)\n",
    "        \n",
    "    train_acc4_classes.append(train_acc_class)\n",
    "    train_sen4_classes.append(train_sen_class)\n",
    "    train_spe4_classes.append(train_spe_class)\n",
    "    \n",
    "    #test\n",
    "    cm = confusion_matrix(y_test4, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "    test_acc_class = []\n",
    "    test_sen_class = []\n",
    "    test_spe_class = []\n",
    "    \n",
    "    for i in range(5):  \n",
    "        TP = cm[i][i]\n",
    "        FN = cm[i].sum() - TP\n",
    "        FP = cm.T[i].sum() - TP\n",
    "        TN = cm.sum() - TP - FN - FP\n",
    "        accuracy = (TP+TN)/cm.sum()\n",
    "        sensitivity = TP/(TP+FN)\n",
    "        specificity = TN/(TN+FP)\n",
    "        \n",
    "        test_acc_class.append(accuracy)\n",
    "        test_sen_class.append(sensitivity)\n",
    "        test_spe_class.append(specificity)\n",
    "        \n",
    "    test_acc4_classes.append(test_acc_class)\n",
    "    test_sen4_classes.append(test_sen_class)\n",
    "    test_spe4_classes.append(test_spe_class)  \n",
    "    \n",
    "    #calculate errors\n",
    "    mis_train_error_4 = abs(y_train4 - bagging_train_pred)\n",
    "    mis_test_error_4 = abs(y_test4 - bagging_test_pred)\n",
    "    \n",
    "    c = 0\n",
    "    for i, j in zip(mis_train_error_4, train_indexs[0]):\n",
    "        if j not in mis_train_1 and j not in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_1[c] = i\n",
    "        elif j in mis_train_1 and j not in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j not in mis_train_1 and j in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j not in mis_train_1 and j not in mis_train_2 and j in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j in mis_train_1 and j in mis_train_2 and j not in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j not in mis_train_1 and j in mis_train_2 and j in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        elif j in mis_train_1 and j not in mis_train_2 and j in mis_train_3:\n",
    "            mis_train_error_4[c] = 0\n",
    "            mis_train_error_2[c] = i\n",
    "        c += 1\n",
    "     \n",
    "    c = 0\n",
    "    for i, j in zip(mis_test_error_4, test_indexs[0]):\n",
    "        if j not in mis_test_1 and j not in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_1[c] = i\n",
    "        elif j in mis_test_1 and j not in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j not in mis_test_1 and j in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j not in mis_test_1 and j not in mis_test_2 and j in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j in mis_test_1 and j in mis_test_2 and j not in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j not in mis_test_1 and j in mis_test_2 and j in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        elif j in mis_test_1 and j not in mis_test_2 and j in mis_test_3:\n",
    "            mis_test_error_4[c] = 0\n",
    "            mis_test_error_2[c] = i\n",
    "        c += 1\n",
    "        \n",
    "    #track\n",
    "    #train\n",
    "    for i, j in zip(mis_train_error_4, train_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_train_4.append(j)\n",
    "    \n",
    "    #test\n",
    "    for i, j in zip(mis_test_error_4, test_indexs[0]):\n",
    "        if i != 0:\n",
    "            mis_test_4.append(j)\n",
    "        \n",
    "    cost4.append(len(mis_train_4)+len(mis_test_4))  \n",
    "    \n",
    "    #Weighted Mean Squared Error\n",
    "    wmse_train = {}\n",
    "    for index, one, two, three, four in zip(train_indexs[0], mis_train_error_1, mis_train_error_2, mis_train_error_3, mis_train_error_4):\n",
    "        wmse_train[index] = one**2 * (1/10) + two**2 * (2/10) + three**2 * (3/10) + four**2 * (4/10)\n",
    "        \n",
    "    wmse_test = {}\n",
    "    for index, one, two, three, four in zip(test_indexs[0], mis_test_error_1, mis_test_error_2, mis_test_error_3, mis_test_error_4):\n",
    "        wmse_test[index] = one**2 * (1/10) + two**2 * (2/10) + three**2 * (3/10) + four**2 * (4/10)\n",
    "\n",
    "    for key, value in wmse_train.items():\n",
    "        all_variance[key] = all_variance[key] + value\n",
    "        \n",
    "    for key, value in wmse_test.items():\n",
    "        all_variance[key] = all_variance[key] + value\n",
    "        \n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64383469219 0.678606640671 0.71098156682 0.731585017133\n"
     ]
    }
   ],
   "source": [
    "ave_acc1 = sum(train_acc1)/len(train_acc1)\n",
    "ave_acc2 = sum(train_acc2)/len(train_acc2)\n",
    "ave_acc3 = sum(train_acc3)/len(train_acc3)\n",
    "ave_acc4 = sum(train_acc4)/len(train_acc4)\n",
    "\n",
    "print(ave_acc1, ave_acc2, ave_acc3, ave_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.461990022173 0.537505543237 0.582176644494 0.621644493718\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "\n",
    "ave_acc1 = sum(test_acc1)/len(test_acc1)\n",
    "ave_acc2 = sum(test_acc2)/len(test_acc2)\n",
    "ave_acc3 = sum(test_acc3)/len(test_acc3)\n",
    "ave_acc4 = sum(test_acc4)/len(test_acc4)\n",
    "\n",
    "print(ave_acc1, ave_acc2, ave_acc3, ave_acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration1 sensitivity class1 0.76603674532 class2 0.754717248771 class3 0.480902512347 class1 0.619206956102 class1 0.817907194916\n",
      "Iteration2 sensitivity class1 0.826406669628 class2 0.71151311593 class3 0.514770780689 class1 0.736315634355 class1 0.886806342825\n",
      "Iteration3 sensitivity class1 0.890993184687 class2 0.77507504341 class3 0.510297139975 class1 0.758364087975 class1 0.868344188908\n",
      "Iteration4 sensitivity class1 0.882596840574 class2 0.754436643029 class3 0.566063615647 class1 0.769538993811 class1 0.857269388781\n"
     ]
    }
   ],
   "source": [
    "#Iteration 1 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_sen1_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration1 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 2 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_sen2_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration2 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 3 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_sen3_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration3 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 4 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_sen4_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration4 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration1 sensitivity class1 0.712049450549 class2 0.448856715367 class3 0.303694400837 class4 0.344448260073 class5 0.710636645963\n",
      "Iteration2 sensitivity class1 0.769362020829 class2 0.498409868357 class3 0.343578825134 class4 0.589056656497 class5 0.823138301972\n",
      "Iteration3 sensitivity class1 0.794635450437 class2 0.658145116512 class3 0.384946631251 class4 0.656142239614 class5 0.810911118643\n",
      "Iteration4 test sensitivity class1 0.796136752137 class2 0.649061389504 class3 0.408005848968 class4 0.697159853344 class5 0.817536723968\n"
     ]
    }
   ],
   "source": [
    "# Iteration 1 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in test_sen1_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration1 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class4\", sum(class4)/len(class4), \"class5\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 2 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in test_sen2_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration2 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class4\", sum(class4)/len(class4), \"class5\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 3 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in test_sen3_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration3 sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class4\", sum(class4)/len(class4), \"class5\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 4 Sensitivity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in test_sen4_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration4 test sensitivity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class4\", sum(class4)/len(class4), \"class5\", sum(class5)/len(class5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration1 specificity class1 0.979350073315 class2 0.856795549359 class3 0.898942373225 class1 0.901369913871 class1 0.91267967733\n",
      "Iteration2 specificity class1 0.985399121992 class2 0.884872238765 class3 0.908341513812 class1 0.883035039113 class1 0.930085575452\n",
      "Iteration3 specificity class1 0.988355247359 class2 0.889813239371 class3 0.918938095919 class1 0.890344766264 class1 0.938823236666\n",
      "Iteration4 specificity class1 0.988360577242 class2 0.897498844516 class3 0.917546833491 class1 0.90076855233 class1 0.944434094882\n"
     ]
    }
   ],
   "source": [
    "#Iteration 1 Specificity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_spe1_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration1 specificity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 2 Specificity \n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_spe2_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration2 specificity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 3 Specificity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_spe3_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration3 specificity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))\n",
    "\n",
    "#Iteration 4 Specificity\n",
    "class1 = []\n",
    "class2 = []\n",
    "class3 = []\n",
    "class4 = []\n",
    "class5 = []\n",
    "for I in train_spe4_classes:\n",
    "    class1.append(I[0])\n",
    "    class2.append(I[1])\n",
    "    class3.append(I[2])\n",
    "    class4.append(I[3])\n",
    "    class5.append(I[4])\n",
    "    \n",
    "print(\"Iteration4 specificity\", \"class1\", sum(class1)/len(class1), \"class2\", sum(class2)/len(class2),\n",
    "      \"class3\", sum(class3)/len(class3), \"class1\", sum(class4)/len(class4), \"class1\", sum(class5)/len(class5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IH\n",
    "for key, value in all_variance.items():\n",
    "    all_variance[key] = all_variance[key]/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " cost 1507\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\", \"cost\", int(815 + sum(cost1)/len(cost1) + sum(cost2)/len(cost2) + sum(cost3)/len(cost3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add IH into dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['IH'] = 0\n",
    "for key, value in all_variance.items():\n",
    "    df.loc[key,'IH'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['IH'] = 0\n",
    "\n",
    "for key, value in all_count.items():\n",
    "    df.loc[key,'IH'] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness  ...    \\\n",
       "0        42.803687        35.834900    1.194469     2.073908  ...     \n",
       "1        39.635819        30.844618    1.285016     1.879012  ...     \n",
       "2        18.125068        11.574663    1.565926     1.308681  ...     \n",
       "3        18.324991        17.321312    1.057945     1.117274  ...     \n",
       "4        10.528352         8.908660    1.181811     1.157927  ...     \n",
       "\n",
       "   Malignancy_2  Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  \\\n",
       "0             5             5             4              3              3   \n",
       "1             5             3             4              3              3   \n",
       "2             4             3             2              3              3   \n",
       "3             5             3             2              3              3   \n",
       "4             1             1             1              1              1   \n",
       "\n",
       "   Malignancy3_3  Malignancy3_4  Malignancy3_mode  Propagation     IH  \n",
       "0              3              3                 3            2  0.100  \n",
       "1              2              3                 3            2  0.120  \n",
       "2              2              1                 3            3  0.015  \n",
       "3              2              1                 3            1  1.370  \n",
       "4              1              1                 1            3  0.030  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshape_IH = np.reshape(df[\"IH\"].as_matrix(), (df[\"IH\"].as_matrix().shape[0], 1))\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "min_max_scaler.fit(reshape_IH)\n",
    "IH_norm = min_max_scaler.fit_transform(reshape_IH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"IH_norm\"] = IH_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "      <th>IH_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.370</td>\n",
       "      <td>0.126093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness    ...     \\\n",
       "0        42.803687        35.834900    1.194469     2.073908    ...      \n",
       "1        39.635819        30.844618    1.285016     1.879012    ...      \n",
       "2        18.125068        11.574663    1.565926     1.308681    ...      \n",
       "3        18.324991        17.321312    1.057945     1.117274    ...      \n",
       "4        10.528352         8.908660    1.181811     1.157927    ...      \n",
       "\n",
       "   Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  Malignancy3_3  \\\n",
       "0             5             4              3              3              3   \n",
       "1             3             4              3              3              2   \n",
       "2             3             2              3              3              2   \n",
       "3             3             2              3              3              2   \n",
       "4             1             1              1              1              1   \n",
       "\n",
       "   Malignancy3_4  Malignancy3_mode  Propagation     IH   IH_norm  \n",
       "0              3                 3            2  0.100  0.009204  \n",
       "1              3                 3            2  0.120  0.011045  \n",
       "2              1                 3            3  0.015  0.001381  \n",
       "3              1                 3            1  1.370  0.126093  \n",
       "4              1                 1            3  0.030  0.002761  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 722.,   65.,   19.,    4.,    0.,    3.,    1.,    0.,    0.,    1.]),\n",
       " array([ 0. ,  0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1192164e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"IH_norm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness    ...     \\\n",
       "0        42.803687        35.834900    1.194469     2.073908    ...      \n",
       "1        39.635819        30.844618    1.285016     1.879012    ...      \n",
       "2        18.125068        11.574663    1.565926     1.308681    ...      \n",
       "3        18.324991        17.321312    1.057945     1.117274    ...      \n",
       "4        10.528352         8.908660    1.181811     1.157927    ...      \n",
       "\n",
       "   Malignancy_2  Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  \\\n",
       "0             5             5             4              3              3   \n",
       "1             5             3             4              3              3   \n",
       "2             4             3             2              3              3   \n",
       "3             5             3             2              3              3   \n",
       "4             1             1             1              1              1   \n",
       "\n",
       "   Malignancy3_3  Malignancy3_4  Malignancy3_mode  Propagation        IH  \n",
       "0              3              3                 3            2  0.000061  \n",
       "1              2              3                 3            2  0.000791  \n",
       "2              2              1                 3            3  0.000183  \n",
       "3              2              1                 3            1  0.002983  \n",
       "4              1              1                 1            3  0.000487  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"IH\"] = df[\"IH\"].as_matrix()/sum(df[\"IH\"].as_matrix())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 256.,  147.,  136.,   97.,   64.,   45.,   30.,   17.,   14.,    9.]),\n",
       " array([ 0.        ,  0.00048706,  0.00097412,  0.00146119,  0.00194825,\n",
       "         0.00243531,  0.00292237,  0.00340944,  0.0038965 ,  0.00438356,\n",
       "         0.00487062]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMQa/JDXG4Jekxhj8ktSY/wM2ruJnNw23WAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109c42f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"IH\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 238.,  201.,  240.,   82.,   24.,   16.,    7.,    3.,    2.,\n",
       "           1.,    1.]),\n",
       " array([ 0.  ,  0.05,  0.1 ,  0.2 ,  0.3 ,  0.4 ,  0.5 ,  0.6 ,  0.7 ,\n",
       "         0.8 ,  0.9 ,  1.  ]),\n",
       " <a list of 11 Patch objects>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a24c23438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df[\"IH\"],bins=[0, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.173866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.160614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.028351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness    ...     \\\n",
       "0        42.803687        35.834900    1.194469     2.073908    ...      \n",
       "1        39.635819        30.844618    1.285016     1.879012    ...      \n",
       "2        18.125068        11.574663    1.565926     1.308681    ...      \n",
       "3        18.324991        17.321312    1.057945     1.117274    ...      \n",
       "4        10.528352         8.908660    1.181811     1.157927    ...      \n",
       "\n",
       "   Malignancy_2  Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  \\\n",
       "0             5             5             4              3              3   \n",
       "1             5             3             4              3              3   \n",
       "2             4             3             2              3              3   \n",
       "3             5             3             2              3              3   \n",
       "4             1             1             1              1              1   \n",
       "\n",
       "   Malignancy3_3  Malignancy3_4  Malignancy3_mode  Propagation        IH  \n",
       "0              3              3                 3            2  0.000000  \n",
       "1              2              3                 3            2  0.173866  \n",
       "2              2              1                 3            3  0.005670  \n",
       "3              2              1                 3            1  0.160614  \n",
       "4              1              1                 1            3  0.028351  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"IH\"] = IH_norm\n",
    "df.drop(['IH_norm'], inplace = True, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"LIDC with IH(MSE).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"LIDC with IH Right.csv\", index_col = \"noduleID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noduleID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.063571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.082643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.334286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.267429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0  Area  ConvexArea   Perimeter  ConvexPerimeter  \\\n",
       "noduleID                                                              \n",
       "1                  0  1094        1286  168.852814       135.372918   \n",
       "3                  1   931        1062  148.267027       119.799290   \n",
       "4                  2   161         167   51.455844        49.201081   \n",
       "5                  3   246         251   58.769553        57.721132   \n",
       "6                  4    71          73   32.142136        31.494737   \n",
       "\n",
       "          EquivDiameter  MajorAxisLength  MinorAxisLength  Elongation  \\\n",
       "noduleID                                                                \n",
       "1             37.321898        42.803687        35.834900    1.194469   \n",
       "3             34.429435        39.635819        30.844618    1.285016   \n",
       "4             14.317527        18.125068        11.574663    1.565926   \n",
       "5             17.697936        18.324991        17.321312    1.057945   \n",
       "6              9.507892        10.528352         8.908660    1.181811   \n",
       "\n",
       "          Compactness    ...     Malignancy_2  Malignancy_3  Malignancy_4  \\\n",
       "noduleID                 ...                                                \n",
       "1            2.073908    ...                5             5             4   \n",
       "3            1.879012    ...                5             3             4   \n",
       "4            1.308681    ...                4             3             2   \n",
       "5            1.117274    ...                5             3             2   \n",
       "6            1.157927    ...                1             1             1   \n",
       "\n",
       "          Malignancy3_1  Malignancy3_2  Malignancy3_3  Malignancy3_4  \\\n",
       "noduleID                                                               \n",
       "1                     3              3              3              3   \n",
       "3                     3              3              2              3   \n",
       "4                     3              3              2              1   \n",
       "5                     3              3              2              1   \n",
       "6                     1              1              1              1   \n",
       "\n",
       "          Malignancy3_mode  Propagation        IH  \n",
       "noduleID                                           \n",
       "1                        3            5  0.063571  \n",
       "3                        3            5  0.082643  \n",
       "4                        3            3  0.334286  \n",
       "5                        3            3  0.157500  \n",
       "6                        1            2  0.267429  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_ratings = pd.read_csv(\"LIDC_20130817_AllFeatures2D_MaxSlicePerNodule_inLineRatings.csv\", index_col = \"noduleID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all_ratings = df_all_ratings[[\"Subtlety_1\", \"Subtlety_2\", \"Subtlety_3\", \"Subtlety_4\", \"InternalStructure_1\", \n",
    "               \"InternalStructure_2\", \"InternalStructure_3\", \"InternalStructure_4\", \"Calcification_1\",\n",
    "               \"Calcification_2\", \"Calcification_3\", \"Calcification_4\", \"Sphericity_1\", \"Sphericity_2\",\n",
    "               \"Sphericity_3\", \"Sphericity_4\", \"Margin_1\", \"Margin_2\", \"Margin_3\", \"Margin_4\", \"Lobulation_1\",\n",
    "               \"Lobulation_2\", \"Lobulation_3\", \"Lobulation_4\", \"Spiculation_1\", \"Spiculation_2\",\n",
    "               \"Spiculation_3\", \"Spiculation_4\", \"Texture_1\", \"Texture_2\", \"Texture_3\", \"Texture_4\", \"Malignancy_1\",\n",
    "               \"Malignancy_2\", \"Malignancy_3\", \"Malignancy_4\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    value,counts = np.unique(labels, return_counts=True)\n",
    "    return stats.entropy(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seperate data into an easy group and a hard group\n",
    "hardID = []\n",
    "easyID = []\n",
    "for index, row in df.iterrows():\n",
    "    if row['IH'] > 0.557142857:\n",
    "        hardID.append(index)\n",
    "    elif row['IH'] == 0:\n",
    "        easyID.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hardID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "easyID = random.choices(easyID, k=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(easyID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hard\n",
    "Subtlety_hard_var = []\n",
    "InternalStructure_hard_var = []\n",
    "Calcification_hard_var = []\n",
    "Sphericity_hard_var = []\n",
    "Margin_hard_var = []\n",
    "Lobulation_hard_var = []\n",
    "Spiculation_hard_var = []\n",
    "Texture_hard_var = []\n",
    "Malignancy_hard_var = []\n",
    "\n",
    "for i in hardID:\n",
    "    #Subtlety\n",
    "    Su_1 = df_all_ratings.loc[i][\"Subtlety_1\"]\n",
    "    Su_2 = df_all_ratings.loc[i][\"Subtlety_2\"]\n",
    "    Su_3 = df_all_ratings.loc[i][\"Subtlety_3\"]\n",
    "    Su_4 = df_all_ratings.loc[i][\"Subtlety_4\"]\n",
    "    \n",
    "    Subtlety = np.array([Su_1, Su_2, Su_3, Su_4])\n",
    "    Subtlety_hard_var.append(entropy(Subtlety))\n",
    "    \n",
    "    #InternalStructure\n",
    "    IS_1 = df_all_ratings.loc[i][\"InternalStructure_1\"]\n",
    "    IS_2 = df_all_ratings.loc[i][\"InternalStructure_2\"]\n",
    "    IS_3 = df_all_ratings.loc[i][\"InternalStructure_3\"]\n",
    "    IS_4 = df_all_ratings.loc[i][\"InternalStructure_4\"]\n",
    "    \n",
    "    InternalStructure = np.array([IS_1, IS_2, IS_3, IS_4])\n",
    "    InternalStructure_hard_var.append(entropy(InternalStructure_hard_var))\n",
    "    \n",
    "    #Calcification\n",
    "    Ca_1 = df_all_ratings.loc[i][\"Calcification_1\"]\n",
    "    Ca_2 = df_all_ratings.loc[i][\"Calcification_2\"]\n",
    "    Ca_3 = df_all_ratings.loc[i][\"Calcification_3\"]\n",
    "    Ca_4 = df_all_ratings.loc[i][\"Calcification_4\"]\n",
    "    \n",
    "    Calcification = np.array([Ca_1, Ca_2, Ca_3, Ca_4])\n",
    "    Calcification_hard_var.append(entropy(Calcification))\n",
    "    \n",
    "    #Sphericity\n",
    "    Sp_1 = df_all_ratings.loc[i][\"Sphericity_1\"]\n",
    "    Sp_2 = df_all_ratings.loc[i][\"Sphericity_2\"]\n",
    "    Sp_3 = df_all_ratings.loc[i][\"Sphericity_3\"]\n",
    "    Sp_4 = df_all_ratings.loc[i][\"Sphericity_4\"]\n",
    "    \n",
    "    Sphericity = np.array([Sp_1, Sp_2, Sp_3, Sp_4])\n",
    "    Sphericity_hard_var.append(entropy(Sphericity))\n",
    "    \n",
    "    #Margin\n",
    "    Ma_1 = df_all_ratings.loc[i][\"Margin_1\"]\n",
    "    Ma_2 = df_all_ratings.loc[i][\"Margin_2\"]\n",
    "    Ma_3 = df_all_ratings.loc[i][\"Margin_3\"]\n",
    "    Ma_4 = df_all_ratings.loc[i][\"Margin_4\"]\n",
    "    \n",
    "    Margin = np.array([Ma_1, Ma_2, Ma_3, Ma_4])\n",
    "    Margin_hard_var.append(entropy(Margin))\n",
    "    \n",
    "    #Lobulation\n",
    "    Lo_1 = df_all_ratings.loc[i][\"Lobulation_1\"]\n",
    "    Lo_2 = df_all_ratings.loc[i][\"Lobulation_2\"]\n",
    "    Lo_3 = df_all_ratings.loc[i][\"Lobulation_3\"]\n",
    "    Lo_4 = df_all_ratings.loc[i][\"Lobulation_4\"]\n",
    "    \n",
    "    Lobulation = np.array([Lo_1, Lo_2, Lo_3, Lo_4])\n",
    "    Lobulation_hard_var.append(entropy(Lobulation))\n",
    "    \n",
    "    #Spiculation\n",
    "    Spi_1 = df_all_ratings.loc[i][\"Spiculation_1\"]\n",
    "    Spi_2 = df_all_ratings.loc[i][\"Spiculation_2\"]\n",
    "    Spi_3 = df_all_ratings.loc[i][\"Spiculation_3\"]\n",
    "    Spi_4 = df_all_ratings.loc[i][\"Spiculation_4\"]\n",
    "    \n",
    "    Spiculation = np.array([Spi_1, Spi_2, Spi_3, Spi_4])\n",
    "    Spiculation_hard_var.append(entropy(Spiculation))\n",
    "    \n",
    "    #Texture\n",
    "    Te_1 = df_all_ratings.loc[i][\"Texture_1\"]\n",
    "    Te_2 = df_all_ratings.loc[i][\"Texture_2\"]\n",
    "    Te_3 = df_all_ratings.loc[i][\"Texture_3\"]\n",
    "    Te_4 = df_all_ratings.loc[i][\"Texture_4\"]\n",
    "    \n",
    "    Texture = np.array([Te_1, Te_2, Te_3, Te_4])\n",
    "    Texture_hard_var.append(entropy(Texture))\n",
    "    \n",
    "    \n",
    "    #Malignancy\n",
    "    Mal_1 = df_all_ratings.loc[i][\"Malignancy_1\"]\n",
    "    Mal_2 = df_all_ratings.loc[i][\"Malignancy_2\"]\n",
    "    Mal_3 = df_all_ratings.loc[i][\"Malignancy_3\"]\n",
    "    Mal_4 = df_all_ratings.loc[i][\"Malignancy_4\"]\n",
    "    \n",
    "    Malignancy = np.array([Mal_1, Mal_2, Mal_3, Mal_4])\n",
    "    Malignancy_hard_var.append(entropy(Malignancy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "easyID.remove(1727)\n",
    "easyID.remove(1725)\n",
    "easyID.remove(2214)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# easy\n",
    "Subtlety_easy_var = []\n",
    "InternalStructure_easy_var = []\n",
    "Calcification_easy_var = []\n",
    "Sphericity_easy_var = []\n",
    "Margin_easy_var = []\n",
    "Lobulation_easy_var = []\n",
    "Spiculation_easy_var = []\n",
    "Texture_easy_var = []\n",
    "Malignancy_easy_var = []\n",
    "\n",
    "for i in easyID:\n",
    "    #Subtlety\n",
    "    Su_1 = df_all_ratings.loc[i][\"Subtlety_1\"]\n",
    "    Su_2 = df_all_ratings.loc[i][\"Subtlety_2\"]\n",
    "    Su_3 = df_all_ratings.loc[i][\"Subtlety_3\"]\n",
    "    Su_4 = df_all_ratings.loc[i][\"Subtlety_4\"]\n",
    "    \n",
    "    Subtlety = np.array([Su_1, Su_2, Su_3, Su_4])\n",
    "    Subtlety_easy_var.append(entropy(Subtlety))\n",
    "    \n",
    "    #InternalStructure\n",
    "    IS_1 = df_all_ratings.loc[i][\"InternalStructure_1\"]\n",
    "    IS_2 = df_all_ratings.loc[i][\"InternalStructure_2\"]\n",
    "    IS_3 = df_all_ratings.loc[i][\"InternalStructure_3\"]\n",
    "    IS_4 = df_all_ratings.loc[i][\"InternalStructure_4\"]\n",
    "    \n",
    "    InternalStructure = np.array([IS_1, IS_2, IS_3, IS_4])\n",
    "    InternalStructure_easy_var.append(entropy(InternalStructure))\n",
    "    \n",
    "    #Calcification\n",
    "    Ca_1 = df_all_ratings.loc[i][\"Calcification_1\"]\n",
    "    Ca_2 = df_all_ratings.loc[i][\"Calcification_2\"]\n",
    "    Ca_3 = df_all_ratings.loc[i][\"Calcification_3\"]\n",
    "    Ca_4 = df_all_ratings.loc[i][\"Calcification_4\"]\n",
    "    \n",
    "    Calcification = np.array([Ca_1, Ca_2, Ca_3, Ca_4])\n",
    "    Calcification_easy_var.append(entropy(Calcification))\n",
    "    \n",
    "    #Sphericity\n",
    "    Sp_1 = df_all_ratings.loc[i][\"Sphericity_1\"]\n",
    "    Sp_2 = df_all_ratings.loc[i][\"Sphericity_2\"]\n",
    "    Sp_3 = df_all_ratings.loc[i][\"Sphericity_3\"]\n",
    "    Sp_4 = df_all_ratings.loc[i][\"Sphericity_4\"]\n",
    "    \n",
    "    Sphericity = np.array([Sp_1, Sp_2, Sp_3, Sp_4])\n",
    "    Sphericity_easy_var.append(entropy(Sphericity))\n",
    "    \n",
    "    #Margin\n",
    "    Ma_1 = df_all_ratings.loc[i][\"Margin_1\"]\n",
    "    Ma_2 = df_all_ratings.loc[i][\"Margin_2\"]\n",
    "    Ma_3 = df_all_ratings.loc[i][\"Margin_3\"]\n",
    "    Ma_4 = df_all_ratings.loc[i][\"Margin_4\"]\n",
    "    \n",
    "    Margin = np.array([Ma_1, Ma_2, Ma_3, Ma_4])\n",
    "    Margin_easy_var.append(entropy(Margin))\n",
    "    \n",
    "    #Lobulation\n",
    "    Lo_1 = df_all_ratings.loc[i][\"Lobulation_1\"]\n",
    "    Lo_2 = df_all_ratings.loc[i][\"Lobulation_2\"]\n",
    "    Lo_3 = df_all_ratings.loc[i][\"Lobulation_3\"]\n",
    "    Lo_4 = df_all_ratings.loc[i][\"Lobulation_4\"]\n",
    "    \n",
    "    Lobulation = np.array([Lo_1, Lo_2, Lo_3, Lo_4])\n",
    "    Lobulation_easy_var.append(entropy(Lobulation))\n",
    "    \n",
    "    #Spiculation\n",
    "    Spi_1 = df_all_ratings.loc[i][\"Spiculation_1\"]\n",
    "    Spi_2 = df_all_ratings.loc[i][\"Spiculation_2\"]\n",
    "    Spi_3 = df_all_ratings.loc[i][\"Spiculation_3\"]\n",
    "    Spi_4 = df_all_ratings.loc[i][\"Spiculation_4\"]\n",
    "    \n",
    "    Spiculation = np.array([Spi_1, Spi_2, Spi_3, Spi_4])\n",
    "    Spiculation_easy_var.append(entropy(Spiculation))\n",
    "    \n",
    "    #Texture\n",
    "    Te_1 = df_all_ratings.loc[i][\"Texture_1\"]\n",
    "    Te_2 = df_all_ratings.loc[i][\"Texture_2\"]\n",
    "    Te_3 = df_all_ratings.loc[i][\"Texture_3\"]\n",
    "    Te_4 = df_all_ratings.loc[i][\"Texture_4\"]\n",
    "    \n",
    "    Texture = np.array([Te_1, Te_2, Te_3, Te_4])\n",
    "    Texture_easy_var.append(entropy(Texture))\n",
    "    \n",
    "    \n",
    "    #Malignancy\n",
    "    Mal_1 = df_all_ratings.loc[i][\"Malignancy_1\"]\n",
    "    Mal_2 = df_all_ratings.loc[i][\"Malignancy_2\"]\n",
    "    Mal_3 = df_all_ratings.loc[i][\"Malignancy_3\"]\n",
    "    Mal_4 = df_all_ratings.loc[i][\"Malignancy_4\"]\n",
    "    \n",
    "    Malignancy = np.array([Mal_1, Mal_2, Mal_3, Mal_4])\n",
    "    Malignancy_easy_var.append(entropy(Malignancy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.4751529252986935, pvalue=0.14687448984717852)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Subtlety_easy_var, Subtlety_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69071057588 0.610307015413\n"
     ]
    }
   ],
   "source": [
    "print(sum(Subtlety_easy_var)/len(Subtlety_easy_var), sum(Subtlety_hard_var)/len(Subtlety_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.4731004791216309, pvalue=0.00054313446676465549)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(InternalStructure_easy_var, InternalStructure_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0267778640295 0.0\n"
     ]
    }
   ],
   "source": [
    "print(sum(InternalStructure_easy_var)/len(InternalStructure_easy_var), sum(InternalStructure_hard_var)/len(InternalStructure_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2.6118221649803246, pvalue=0.012363621838003448)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Calcification_easy_var, Calcification_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.100663392101 0.252528422525\n"
     ]
    }
   ],
   "source": [
    "print(sum(Calcification_easy_var)/len(Calcification_easy_var), sum(Calcification_hard_var)/len(Calcification_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-1.231694665121466, pvalue=0.22405611200694375)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Sphericity_easy_var, Sphericity_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.758554169176 0.808349067001\n"
     ]
    }
   ],
   "source": [
    "print(sum(Sphericity_easy_var)/len(Sphericity_easy_var), sum(Sphericity_hard_var)/len(Sphericity_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=2.9534167845897912, pvalue=0.0049812418324343428)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Margin_easy_var, Margin_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.664273503574 0.481393553305\n"
     ]
    }
   ],
   "source": [
    "print(sum(Margin_easy_var)/len(Margin_easy_var), sum(Margin_hard_var)/len(Margin_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.67189806703183175, pvalue=0.50503657474247943)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Lobulation_easy_var, Lobulation_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608761857744 0.567025647084\n"
     ]
    }
   ],
   "source": [
    "print(sum(Lobulation_easy_var)/len(Lobulation_easy_var), sum(Lobulation_hard_var)/len(Lobulation_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.15477869288582716, pvalue=0.87767724077552933)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Spiculation_easy_var, Spiculation_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.501641565364 0.511285989619\n"
     ]
    }
   ],
   "source": [
    "print(sum(Spiculation_easy_var)/len(Spiculation_easy_var), sum(Spiculation_hard_var)/len(Spiculation_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=4.4366636899189213, pvalue=4.870006175691751e-05)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Texture_easy_var, Texture_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.305460331267 0.126729532701\n"
     ]
    }
   ],
   "source": [
    "print(sum(Texture_easy_var)/len(Texture_easy_var), sum(Texture_hard_var)/len(Texture_hard_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=5.5688396578176214, pvalue=1.3730099328140923e-06)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(Malignancy_easy_var, Malignancy_hard_var, equal_var = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.672275817447 0.41740214369\n"
     ]
    }
   ],
   "source": [
    "print(sum(Malignancy_easy_var)/len(Malignancy_easy_var), sum(Malignancy_hard_var)/len(Malignancy_hard_var))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
