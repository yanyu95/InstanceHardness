{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import scipy.stats\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import statistics\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.utils import resample\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness    ...     \\\n",
       "0        42.803687        35.834900    1.194469     2.073908    ...      \n",
       "1        39.635819        30.844618    1.285016     1.879012    ...      \n",
       "2        18.125068        11.574663    1.565926     1.308681    ...      \n",
       "3        18.324991        17.321312    1.057945     1.117274    ...      \n",
       "4        10.528352         8.908660    1.181811     1.157927    ...      \n",
       "\n",
       "   Malignancy_2  Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  \\\n",
       "0             5             5             4              3              3   \n",
       "1             5             3             4              3              3   \n",
       "2             4             3             2              3              3   \n",
       "3             5             3             2              3              3   \n",
       "4             1             1             1              1              1   \n",
       "\n",
       "   Malignancy3_3  Malignancy3_4  Malignancy3_mode  Propagation        IH  \n",
       "0              3              3                 3            2  0.009204  \n",
       "1              2              3                 3            2  0.011045  \n",
       "2              2              1                 3            3  0.001381  \n",
       "3              2              1                 3            1  0.126093  \n",
       "4              1              1                 1            3  0.002761  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"LIDC with IH(MSE).csv\", index_col = \"Unnamed: 0\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noduleID</th>\n",
       "      <th>Area</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>ConvexPerimeter</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>Elongation</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>...</th>\n",
       "      <th>Malignancy_2</th>\n",
       "      <th>Malignancy_3</th>\n",
       "      <th>Malignancy_4</th>\n",
       "      <th>Malignancy3_1</th>\n",
       "      <th>Malignancy3_2</th>\n",
       "      <th>Malignancy3_3</th>\n",
       "      <th>Malignancy3_4</th>\n",
       "      <th>Malignancy3_mode</th>\n",
       "      <th>Propagation</th>\n",
       "      <th>IH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1094</td>\n",
       "      <td>1286</td>\n",
       "      <td>168.852814</td>\n",
       "      <td>135.372918</td>\n",
       "      <td>37.321898</td>\n",
       "      <td>42.803687</td>\n",
       "      <td>35.834900</td>\n",
       "      <td>1.194469</td>\n",
       "      <td>2.073908</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>1062</td>\n",
       "      <td>148.267027</td>\n",
       "      <td>119.799290</td>\n",
       "      <td>34.429435</td>\n",
       "      <td>39.635819</td>\n",
       "      <td>30.844618</td>\n",
       "      <td>1.285016</td>\n",
       "      <td>1.879012</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>161</td>\n",
       "      <td>167</td>\n",
       "      <td>51.455844</td>\n",
       "      <td>49.201081</td>\n",
       "      <td>14.317527</td>\n",
       "      <td>18.125068</td>\n",
       "      <td>11.574663</td>\n",
       "      <td>1.565926</td>\n",
       "      <td>1.308681</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>246</td>\n",
       "      <td>251</td>\n",
       "      <td>58.769553</td>\n",
       "      <td>57.721132</td>\n",
       "      <td>17.697936</td>\n",
       "      <td>18.324991</td>\n",
       "      <td>17.321312</td>\n",
       "      <td>1.057945</td>\n",
       "      <td>1.117274</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.126093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>71</td>\n",
       "      <td>73</td>\n",
       "      <td>32.142136</td>\n",
       "      <td>31.494737</td>\n",
       "      <td>9.507892</td>\n",
       "      <td>10.528352</td>\n",
       "      <td>8.908660</td>\n",
       "      <td>1.181811</td>\n",
       "      <td>1.157927</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noduleID  Area  ConvexArea   Perimeter  ConvexPerimeter  EquivDiameter  \\\n",
       "0         1  1094        1286  168.852814       135.372918      37.321898   \n",
       "1         3   931        1062  148.267027       119.799290      34.429435   \n",
       "2         4   161         167   51.455844        49.201081      14.317527   \n",
       "3         5   246         251   58.769553        57.721132      17.697936   \n",
       "4         6    71          73   32.142136        31.494737       9.507892   \n",
       "\n",
       "   MajorAxisLength  MinorAxisLength  Elongation  Compactness    ...     \\\n",
       "0        42.803687        35.834900    1.194469     2.073908    ...      \n",
       "1        39.635819        30.844618    1.285016     1.879012    ...      \n",
       "2        18.125068        11.574663    1.565926     1.308681    ...      \n",
       "3        18.324991        17.321312    1.057945     1.117274    ...      \n",
       "4        10.528352         8.908660    1.181811     1.157927    ...      \n",
       "\n",
       "   Malignancy_2  Malignancy_3  Malignancy_4  Malignancy3_1  Malignancy3_2  \\\n",
       "0             5             5             4              3              3   \n",
       "1             5             3             4              3              3   \n",
       "2             4             3             2              3              3   \n",
       "3             5             3             2              3              3   \n",
       "4             1             1             1              1              1   \n",
       "\n",
       "   Malignancy3_3  Malignancy3_4  Malignancy3_mode  Propagation        IH  \n",
       "0              3              3                 3            2  0.009204  \n",
       "1              2              3                 3            2  0.011045  \n",
       "2              2              1                 3            3  0.001381  \n",
       "3              2              1                 3            1  0.126093  \n",
       "4              1              1                 1            3  0.002761  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df[df.IH != 0]\n",
    "df.loc[df.IH == 0, 'IH'] = 0.0001\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop([\"noduleID\",'Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4',\n",
    "    \"Malignancy3_1\", 'Malignancy3_2', \"Malignancy3_3\", \"Malignancy3_4\", \"Malignancy3_mode\", \"Propagation\", \"IH\"], axis=1)\n",
    "X = X.as_matrix()\n",
    "IH = df[[\"IH\"]]\n",
    "IH = IH.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def subsample(dataset, ratio=0.632):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "   # random.seed(10)\n",
    "    sample_indices = np.random.choice(len(dataset), n_sample)\n",
    "    for i in range(n_sample):\n",
    "        index = sample_indices[i]\n",
    "        sample.append(dataset[index])\n",
    "    sample_asarray = np.asarray(sample)\n",
    "    return sample_asarray\n",
    "\n",
    "def hard_subsample(dataset, ih, hard_quotient, ratio=0.632):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    # Set weights to be a function of IH by adding a certain percentage of IH (as specified by hard_quotient) to weights\n",
    "    w = np.ones(len(dataset)) + [hard_quotient*i for i in ih]   # This way the weights are between 1 and 1.2 if hard_quotient = 0.2 (default)\n",
    "    weights = w / sum(w) # Now sum of all weights equal to one\n",
    "    \n",
    "  #  np.random.seed(10)\n",
    "    sample_indices = np.random.choice(len(dataset), n_sample, p = weights, replace=True)\n",
    "    for i in range(n_sample):\n",
    "        index = sample_indices[i]\n",
    "        sample.append(dataset[index])\n",
    "    sample_asarray = np.asarray(sample)\n",
    "    return sample_asarray\n",
    "\n",
    "def easy_subsample(dataset, ih, hard_quotient, ratio=0.632):\n",
    "    sample = list()\n",
    "    n_sample = round(len(dataset) * ratio)\n",
    "    # Set weights to be a function of IH by adding a certain percentage of IH (as specified by hard_quotient) to weights\n",
    "    easiness = [1 - i for i in ih]\n",
    "    w = np.ones(len(dataset)) + [hard_quotient*i for i in easiness]   # This way the weights are between 1 and 1.2 if hard_quotient = 0.2 (default)\n",
    "    weights = w / sum(w) # Now sum of all weights equal to one\n",
    "    \n",
    "  #  np.random.seed(10)\n",
    "    sample_indices = np.random.choice(len(dataset), n_sample, p = weights, replace=True)\n",
    "    for i in range(n_sample):\n",
    "        index = sample_indices[i]\n",
    "        sample.append(dataset[index])\n",
    "    sample_asarray = np.asarray(sample)\n",
    "    return sample_asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defnumbags = 10 # default number of bags\n",
    "def create_regular_bags(trainset, nbags):\n",
    "    bags = list()\n",
    "    \n",
    "    for i in range(nbags):\n",
    "        bags.append(subsample(trainset))\n",
    "    \n",
    "    bags_asarray = np.asarray(bags)\n",
    "    return bags_asarray\n",
    "\n",
    "def create_mixed_bags(trainset, ih, nbags, mix_ratio, hard_quotient):\n",
    "    neasy = round(nbags*mix_ratio[0]) \n",
    "    nnormal = round(nbags*mix_ratio[1]) \n",
    "    nhard = round(nbags*mix_ratio[2]) \n",
    "    \n",
    "    bags = list()\n",
    "    # Make easy bags\n",
    "    for i in range(neasy):     # First nneasy easy bags    \n",
    "        bags.append(easy_subsample(trainset, ih, hard_quotient))      \n",
    "    # Make normal bags\n",
    "    for i in range(neasy, neasy + nnormal):      # The next nnormal normal bags      \n",
    "        bags.append(subsample(trainset))\n",
    "    # Make hard bags\n",
    "    for i in range(neasy + nnormal, neasy + nnormal + nhard):   # The next nhard hard bags\n",
    "        bags.append(hard_subsample(trainset, ih, hard_quotient))\n",
    "    \n",
    "    bags_asarray = np.asarray(bags)\n",
    "    return bags_asarray\n",
    "\n",
    "def create_gradually_mixed_bags(trainset, ih, nbags, low_bag_hardness, high_bag_hardness):\n",
    "    bag_hardness_values = np.linspace(low_bag_hardness, high_bag_hardness, nbags)   # Divide up the range to find hardness value for each bag\n",
    "    \n",
    "    bags = list()\n",
    "    \n",
    "    for i in range(nbags):   # nbags = len(hardness_values) \n",
    "        if bag_hardness_values[i] < 0:\n",
    "            bags.append(easy_subsample(trainset, ih, 0 - bag_hardness_values[i]))  # say, bag hardness is -0.3 Thats the same as creating an easy bag with HC =  0.3\n",
    "        elif bag_hardness_values[i] == 0:\n",
    "            bags.append(subsample(trainset))\n",
    "        else:   # if > 1\n",
    "            bags.append(hard_subsample(trainset, ih, bag_hardness_values[i]))  # say, bag_hardness is 0.4. Thats the same as creating a hard bag with HC = 0.4\n",
    "    \n",
    "    bags_asarray = np.asarray(bags)\n",
    "    return bags_asarray   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_models(bags, clf, X_test):\n",
    "    nbags = bags.shape[0]\n",
    "    nfeatures = bags.shape[2] - 2 # because the last two columns are y and ih\n",
    "    \n",
    "    predictions = list()  \n",
    "    predictions_proba = list()\n",
    "\n",
    "    for i in range(nbags):\n",
    "        # Fit and predict (hard as well as soft predictions)\n",
    "        clf.fit(bags[i][:,0:nfeatures], bags[i][:,nfeatures])\n",
    "        predicted = clf.predict(X_test)\n",
    "       # print(predicted.shape)\n",
    "        predictions.append(predicted)\n",
    "        pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "        # Export tree as DOT file for visualization\n",
    "    #    outfilename = \"tree_bag\"+ str(i) + \".dot\" \n",
    "    #    export_graphviz(clf, out_file=outfilename)   # tree_bag1.dot, tree_bag2.dot etc.\n",
    "        \n",
    "        predictions_asarray = np.asarray(predictions)\n",
    "    return predictions_asarray\n",
    "\n",
    "def calculate_pred(predictions):\n",
    "    ninst = predictions.shape[1] # No. of instances\n",
    "    nbags = predictions.shape[0] # No. of bags\n",
    "    \n",
    "    # hard (binary) predictions\n",
    "    final_pred = np.zeros((ninst, 1))\n",
    "    for j in range(ninst):    # for each instance\n",
    "        count = 0\n",
    "        for i in range(nbags):    # find prediction in each bag and do majority vote\n",
    "            if predictions[i, j] == 1:\n",
    "                count = count + 1\n",
    "        final_pred[j] = 1 if count > nbags/5 else 0   # Majority vote\n",
    "\n",
    "    final_pred = []\n",
    "    for prediction in predictions.T:\n",
    "        tp = Counter(prediction)\n",
    "        final_pred.append(tp.most_common()[0][0])\n",
    "\n",
    "    final_pred = np.array(final_pred)\n",
    "    \n",
    "    return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min_samples_split = 2  min_samples_leaf = 1\n",
    "y_all = df[['Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4']]\n",
    "y_all = y_all.as_matrix()\n",
    "y_allt = np.transpose(y_all)\n",
    "np.random.shuffle(y_allt)\n",
    "y_all = np.transpose(y_allt)\n",
    "y = y_all.T[0]\n",
    "\n",
    "    \n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "train_indexs = []\n",
    "test_indexs = []\n",
    "    \n",
    "\n",
    "for train_index, test_index in skf.split(X, y):  \n",
    "    train_indexs.append(train_index)\n",
    "    test_indexs.append(test_index)\n",
    "\n",
    "    \n",
    "y_all_train = y_all[train_indexs[0]]\n",
    "y_all_test = y_all[test_indexs[0]]\n",
    "    \n",
    "X_train = X[train_indexs[0]]\n",
    "X_test = X[test_indexs[0]]\n",
    "\n",
    "IH_train = IH[train_indexs[0]]\n",
    "IH_test = IH[test_indexs[0]]\n",
    "    \n",
    "##First Iteration\n",
    "\n",
    "y_train1 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "y_test1 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "    \n",
    "#train\n",
    "n = 0\n",
    "for index in train_indexs[0]:\n",
    "    y_train1[n] = y_all[index][0]\n",
    "    n += 1 \n",
    "     \n",
    "#test\n",
    "n = 0\n",
    "for index in test_indexs[0]:\n",
    "    y_test1[n] = y_all[index][0]\n",
    "    n += 1\n",
    "    \n",
    "#Only for train\n",
    "y_train1 = np.reshape(y_train1, (y_train1.shape[0], 1)).astype(int)\n",
    "X_train_withlabels = np.concatenate((X_train, y_train1, IH_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#have 20 versions of labels\n",
    "def Mixed_Bagging_SIC(nbags, mix_ratio, hard_quotient):\n",
    "    number  = 1\n",
    "\n",
    "    train_acc1 = []\n",
    "    test_acc1 = []\n",
    "    noftree1 = []\n",
    "\n",
    "    train_acc2 = []\n",
    "    test_acc2 = []\n",
    "    noftree2 = []\n",
    "\n",
    "    train_acc3 = []\n",
    "    test_acc3 = []\n",
    "    noftree3 = []\n",
    "\n",
    "    train_acc4 = []\n",
    "    test_acc4 = []\n",
    "    noftree4 = []\n",
    "\n",
    "    train_acc1_classes = []\n",
    "    train_acc2_classes = []\n",
    "    train_acc3_classes = []\n",
    "    train_acc4_classes = []\n",
    "\n",
    "    train_sen1_classes = []\n",
    "    train_sen2_classes = []\n",
    "    train_sen3_classes = []\n",
    "    train_sen4_classes = []\n",
    "\n",
    "    train_spe1_classes = []\n",
    "    train_spe2_classes = []\n",
    "    train_spe3_classes = []\n",
    "    train_spe4_classes = []\n",
    "\n",
    "    test_acc1_classes = []\n",
    "    test_acc2_classes = []\n",
    "    test_acc3_classes = []\n",
    "    test_acc4_classes = []\n",
    "\n",
    "    test_sen1_classes = []\n",
    "    test_sen2_classes = []\n",
    "    test_sen3_classes = []\n",
    "    test_sen4_classes = []\n",
    "\n",
    "    test_spe1_classes = []\n",
    "    test_spe2_classes = []\n",
    "    test_spe3_classes = []\n",
    "    test_spe4_classes = []\n",
    "\n",
    "\n",
    "    cost1 = []\n",
    "    cost2 = []\n",
    "    cost3 = []\n",
    "    cost4 = []\n",
    "    \n",
    "    trans_IH = np.log(IH)/np.log(10)\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X,trans_IH)\n",
    "\n",
    "    while number <= 20 :\n",
    "\n",
    "        y_all = df[['Malignancy_1', 'Malignancy_2', 'Malignancy_3', 'Malignancy_4']]\n",
    "        y_all = y_all.as_matrix()\n",
    "        y_allt = np.transpose(y_all)\n",
    "        np.random.shuffle(y_allt)\n",
    "        y_all = np.transpose(y_allt)\n",
    "        y = y_all.T[0]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state = 2)\n",
    "\n",
    "        train_indexs = []\n",
    "        test_indexs = []\n",
    "\n",
    "\n",
    "        for train_index, test_index in skf.split(X, y):  \n",
    "            train_indexs.append(train_index)\n",
    "            test_indexs.append(test_index)\n",
    "\n",
    "        X_train = X[train_indexs[0]]\n",
    "        X_test = X[test_indexs[0]]\n",
    "        \n",
    "        y_all_train = y_all[train_indexs[0]]\n",
    "        y_all_test = y_all[test_indexs[0]]\n",
    "        \n",
    "        IH_train = IH[train_indexs[0]]\n",
    "        \n",
    "        ##First Iteration\n",
    "\n",
    "        y_train1 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "        y_test1 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "\n",
    "        #train\n",
    "        n = 0\n",
    "        for index in train_indexs[0]:\n",
    "            y_train1[n] = y_all[index][0]\n",
    "            n += 1 \n",
    "\n",
    "        #test\n",
    "        n = 0\n",
    "        for index in test_indexs[0]:\n",
    "            y_test1[n] = y_all[index][0]\n",
    "            n += 1\n",
    "        \n",
    "        #Predction  \n",
    "        sm = SMOTE(random_state=2)\n",
    "        X_train_balanced, y_train1_balanced = sm.fit_sample(X_train, y_train1)\n",
    "        #predict synthetic IH\n",
    "        p = linreg.predict(X_train_balanced[X_train.shape[0]:])\n",
    "        p = np.exp(p*np.log(10))\n",
    "        IH_train_balanced = np.concatenate((IH_train, p), axis=0)\n",
    "        \n",
    "        y_train1_balanced = np.reshape(y_train1_balanced, (y_train1_balanced.shape[0], 1)).astype(int)\n",
    "        X_train_withlabels = np.concatenate((X_train_balanced, y_train1_balanced, IH_train_balanced), axis=1)\n",
    "\n",
    "        mis_train_1 = []\n",
    "        mis_test_1 = []\n",
    "\n",
    "        mixed_bags = create_mixed_bags(X_train_withlabels, IH_train_balanced.flatten(),\n",
    "                                       nbags, mix_ratio, hard_quotient)\n",
    "        clf = DecisionTreeClassifier(max_depth= 5)\n",
    "        train_pred = make_models(mixed_bags, clf, X_train)\n",
    "        test_pred = make_models(mixed_bags, clf, X_test)\n",
    "        bagging_train_pred= calculate_pred(train_pred)\n",
    "        bagging_test_pred= calculate_pred(test_pred)\n",
    "        \n",
    "        train_acc1.append(accuracy_score(y_train1, bagging_train_pred))\n",
    "        test_acc1.append(accuracy_score(y_test1, bagging_test_pred))\n",
    "\n",
    "        #train\n",
    "        cm = confusion_matrix(y_train1, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "        train_acc_class = []\n",
    "        train_sen_class = []\n",
    "        train_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            train_acc_class.append(accuracy)\n",
    "            train_sen_class.append(sensitivity)\n",
    "            train_spe_class.append(specificity)\n",
    "\n",
    "        train_acc1_classes.append(train_acc_class)\n",
    "        train_sen1_classes.append(train_sen_class)\n",
    "        train_spe1_classes.append(train_spe_class)\n",
    "\n",
    "        #test\n",
    "        cm = confusion_matrix(y_test1, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "        test_acc_class = []\n",
    "        test_sen_class = []\n",
    "        test_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            test_acc_class.append(accuracy)\n",
    "            test_sen_class.append(sensitivity)\n",
    "            test_spe_class.append(specificity)\n",
    "\n",
    "        test_acc1_classes.append(test_acc_class)\n",
    "        test_sen1_classes.append(test_sen_class)\n",
    "        test_spe1_classes.append(test_spe_class)  \n",
    "\n",
    "        #calculate errors\n",
    "        mis_train_error_1 = abs(y_train1 - bagging_train_pred)\n",
    "        mis_test_error_1 = abs(y_test1 - bagging_test_pred)\n",
    "\n",
    "        #track\n",
    "        #train\n",
    "        for i, j in zip(mis_train_error_1, train_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_train_1.append(j) \n",
    "\n",
    "        #test\n",
    "        for i, j in zip(mis_test_error_1, test_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_test_1.append(j)\n",
    "\n",
    "        cost1.append(len(mis_train_1)+len(mis_test_1))\n",
    "\n",
    "        ##Second Iteration\n",
    "\n",
    "        #Update labels\n",
    "\n",
    "        y_train2 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "        y_test2 = np.zeros(y[test_indexs[0]].shape[0])\n",
    "\n",
    "        #train\n",
    "        n = 0\n",
    "        for a, b in zip(mis_train_error_1, y_all_train):                                \n",
    "            if a != 0:\n",
    "                y_train2[n] = int((b[0] + b[1])/2)\n",
    "            else:\n",
    "                y_train2[n] = y_train1[n]\n",
    "            n += 1   \n",
    "\n",
    "        #test\n",
    "        n = 0\n",
    "        for a, b in zip(mis_test_error_1, y_all_test):                                \n",
    "            if a != 0:\n",
    "                y_test2[n] = int((b[0] + b[1])/2)\n",
    "            else:\n",
    "                y_test2[n] = y_test1[n]\n",
    "            n += 1           \n",
    "\n",
    "\n",
    "        #Predction\n",
    "        #Balanced\n",
    "        X_train_balanced, y_train2_balanced = sm.fit_sample(X_train, y_train2)\n",
    "        #predict synthetic IH\n",
    "        p = linreg.predict(X_train_balanced[X_train.shape[0]:])\n",
    "        p = np.exp(p*np.log(10))\n",
    "        IH_train_balanced = np.concatenate((IH_train, p), axis=0)\n",
    "        \n",
    "        y_train2_balanced = np.reshape(y_train2_balanced, (y_train2_balanced.shape[0], 1)).astype(int)\n",
    "        X_train_withlabels = np.concatenate((X_train_balanced, y_train2_balanced, IH_train_balanced), axis=1)\n",
    "\n",
    "        mis_train_2 = []\n",
    "        mis_test_2 = []\n",
    "\n",
    "        mixed_bags = create_mixed_bags(X_train_withlabels, IH_train_balanced.flatten(), \n",
    "                                       nbags, mix_ratio, hard_quotient)\n",
    "        clf = DecisionTreeClassifier(max_depth= 5)\n",
    "        train_pred = make_models(mixed_bags, clf, X_train)\n",
    "        test_pred = make_models(mixed_bags, clf, X_test)\n",
    "        bagging_train_pred= calculate_pred(train_pred)\n",
    "        bagging_test_pred= calculate_pred(test_pred)\n",
    "        \n",
    "        train_acc2.append(accuracy_score(y_train2, bagging_train_pred))\n",
    "        test_acc2.append(accuracy_score(y_test2, bagging_test_pred))\n",
    "\n",
    "        #train\n",
    "        cm = confusion_matrix(y_train2, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "        train_acc_class = []\n",
    "        train_sen_class = []\n",
    "        train_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            train_acc_class.append(accuracy)\n",
    "            train_sen_class.append(sensitivity)\n",
    "            train_spe_class.append(specificity)\n",
    "\n",
    "        train_acc2_classes.append(train_acc_class)\n",
    "        train_sen2_classes.append(train_sen_class)\n",
    "        train_spe2_classes.append(train_spe_class)\n",
    "\n",
    "        #test\n",
    "        cm = confusion_matrix(y_test2, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "        test_acc_class = []\n",
    "        test_sen_class = []\n",
    "        test_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            test_acc_class.append(accuracy)\n",
    "            test_sen_class.append(sensitivity)\n",
    "            test_spe_class.append(specificity)\n",
    "\n",
    "        test_acc2_classes.append(test_acc_class)\n",
    "        test_sen2_classes.append(test_sen_class)\n",
    "        test_spe2_classes.append(test_spe_class)  \n",
    "\n",
    "        #calculate errors\n",
    "        mis_train_error_2 = abs(y_train2 - bagging_train_pred)\n",
    "        mis_test_error_2 = abs(y_test2 - bagging_test_pred)\n",
    "\n",
    "        c = 0\n",
    "        for i, j in zip(mis_train_error_2, train_indexs[0]):\n",
    "            if j not in mis_train_1:\n",
    "                mis_train_error_2[c] = 0\n",
    "                mis_train_error_1[c] = i\n",
    "            c += 1\n",
    "\n",
    "        c = 0\n",
    "        for i, j in zip(mis_test_error_2, test_indexs[0]):\n",
    "            if j not in mis_test_1:\n",
    "                mis_test_error_2[c] = 0\n",
    "                mis_test_error_1[c] = i\n",
    "            c += 1\n",
    "\n",
    "        #track\n",
    "        #train\n",
    "        for i, j in zip(mis_train_error_2, train_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_train_2.append(j)\n",
    "\n",
    "        #test\n",
    "        for i, j in zip(mis_test_error_2, test_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_test_2.append(j)\n",
    "\n",
    "        cost2.append(len(mis_train_2)+len(mis_test_2))\n",
    "\n",
    "        ##Third Iteration\n",
    "\n",
    "        #Update labels\n",
    "\n",
    "        y_train3 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "        y_test3 = np.zeros(y[test_indexs[0]].shape[0])  \n",
    "\n",
    "        #train\n",
    "        n = 0\n",
    "        for a, b, c in zip(mis_train_error_2, y_all_train, train_indexs[0]):                                \n",
    "            if a != 0:\n",
    "                #3 labels\n",
    "                if c in mis_train_1 and c in mis_train_2:\n",
    "                    if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_train3[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                    else:\n",
    "                        y_train3[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "                #2 labels\n",
    "                else:\n",
    "                    y_train3[n] = int((b[0] + b[1])/2)\n",
    "            else:\n",
    "                y_train3[n] = y_train2[n]\n",
    "            n += 1  \n",
    "\n",
    "        #test\n",
    "        n = 0\n",
    "        for a, b, c in zip(mis_test_error_2, y_all_test, test_indexs[0]):                                \n",
    "            if a != 0:\n",
    "                #3 labels\n",
    "                if c in mis_test_1 and c in mis_test_2:\n",
    "                    if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_test3[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                    else:\n",
    "                        y_test3[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "                #2 labels\n",
    "                else:\n",
    "                    y_test3[n] = int((b[0] + b[1])/2)\n",
    "            else:\n",
    "                y_test3[n] = y_test2[n]\n",
    "            n += 1\n",
    "\n",
    "\n",
    "        #Prediction\n",
    "        #Balanced\n",
    "        X_train_balanced, y_train3_balanced = sm.fit_sample(X_train, y_train3)\n",
    "        #predict synthetic IH\n",
    "        p = linreg.predict(X_train_balanced[X_train.shape[0]:])\n",
    "        p = np.exp(p*np.log(10))\n",
    "        IH_train_balanced = np.concatenate((IH_train, p), axis=0)\n",
    "        \n",
    "        y_train3_balanced = np.reshape(y_train3_balanced, (y_train3_balanced.shape[0], 1)).astype(int)\n",
    "        X_train_withlabels = np.concatenate((X_train_balanced, y_train3_balanced, IH_train_balanced), axis=1)\n",
    "\n",
    "        mis_train_3 = []\n",
    "        mis_test_3 = []\n",
    "\n",
    "        mixed_bags = create_mixed_bags(X_train_withlabels, IH_train_balanced.flatten(), \n",
    "                                       nbags, mix_ratio, hard_quotient)\n",
    "        clf = DecisionTreeClassifier(max_depth= 5)\n",
    "        train_pred = make_models(mixed_bags, clf, X_train)\n",
    "        test_pred = make_models(mixed_bags, clf, X_test)\n",
    "        bagging_train_pred= calculate_pred(train_pred)\n",
    "        bagging_test_pred= calculate_pred(test_pred)\n",
    "        \n",
    "        train_acc3.append(accuracy_score(y_train3, bagging_train_pred))\n",
    "        test_acc3.append(accuracy_score(y_test3, bagging_test_pred))\n",
    "\n",
    "        #train\n",
    "        cm = confusion_matrix(y_train3, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "        train_acc_class = []\n",
    "        train_sen_class = []\n",
    "        train_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            train_acc_class.append(accuracy)\n",
    "            train_sen_class.append(sensitivity)\n",
    "            train_spe_class.append(specificity)\n",
    "\n",
    "        train_acc3_classes.append(train_acc_class)\n",
    "        train_sen3_classes.append(train_sen_class)\n",
    "        train_spe3_classes.append(train_spe_class)\n",
    "\n",
    "        #test\n",
    "        cm = confusion_matrix(y_test3, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "        test_acc_class = []\n",
    "        test_sen_class = []\n",
    "        test_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            test_acc_class.append(accuracy)\n",
    "            test_sen_class.append(sensitivity)\n",
    "            test_spe_class.append(specificity)\n",
    "\n",
    "        test_acc3_classes.append(test_acc_class)\n",
    "        test_sen3_classes.append(test_sen_class)\n",
    "        test_spe3_classes.append(test_spe_class)  \n",
    "\n",
    "        #calculate errors\n",
    "        mis_train_error_3 = abs(y_train3 - bagging_train_pred)\n",
    "        mis_test_error_3 = abs(y_test3 - bagging_test_pred)\n",
    "\n",
    "        c = 0\n",
    "        for i, j in zip(mis_train_error_3, train_indexs[0]):\n",
    "            if j not in mis_train_1 and j not in mis_train_2:\n",
    "                mis_train_error_3[c] = 0\n",
    "                mis_train_error_1[c] = i\n",
    "            elif j not in mis_train_1 and j in mis_train_2:\n",
    "                mis_train_error_3[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            elif j in mis_train_1 and j not in mis_train_2:\n",
    "                mis_train_error_3[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            c += 1\n",
    "\n",
    "        c = 0\n",
    "        for i, j in zip(mis_test_error_3, test_indexs[0]):\n",
    "            if j not in mis_test_1 and j not in mis_test_2:\n",
    "                mis_test_error_3[c] = 0\n",
    "                mis_test_error_1[c] = i\n",
    "            elif j not in mis_test_1 and j in mis_test_2:\n",
    "                mis_test_error_3[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            elif j in mis_test_1 and j not in mis_test_2:\n",
    "                mis_test_error_3[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            c += 1\n",
    "\n",
    "        #track\n",
    "        #train\n",
    "        for i, j in zip(mis_train_error_3, train_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_train_3.append(j)\n",
    "\n",
    "        #test\n",
    "        for i, j in zip(mis_test_error_3, test_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_test_3.append(j)\n",
    "\n",
    "        cost3.append(len(mis_train_3)+len(mis_test_3))\n",
    "\n",
    "        ##Fourth Iteration\n",
    "\n",
    "        #Update labels\n",
    "\n",
    "        y_train4 = np.zeros(y[train_indexs[0]].shape[0])\n",
    "        y_test4 = np.zeros(y[test_indexs[0]].shape[0])  \n",
    "\n",
    "        #train\n",
    "        n = 0\n",
    "        for a, b, c in zip(mis_train_error_3, y_all_train, train_indexs[0]):                                \n",
    "            if a != 0:\n",
    "                #4 labels\n",
    "                if c in mis_train_1 and c in mis_train_2 and c in mis_train_3:\n",
    "                    if b[3] == b[0] and b[1] == b[2]:    \n",
    "                        y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    elif b[3] == b[1] and b[0] == b[2]:    \n",
    "                        y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    elif b[3] == b[2] and b[0] == b[1]:    \n",
    "                        y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_train4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    else:\n",
    "                        y_train4[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "\n",
    "                # 3 labels\n",
    "                elif c in mis_train_1 and c in mis_train_3:\n",
    "                    if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_train4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                    else:\n",
    "                        y_train4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "\n",
    "\n",
    "                #3 labels\n",
    "                elif c in mis_train_2 and c in mis_train_3:\n",
    "                    if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_train4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                    else:\n",
    "                        y_train4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "\n",
    "\n",
    "                #2 labels\n",
    "                else:\n",
    "                    y_train4[n] = int((b[0] + b[1])/2)\n",
    "            else:\n",
    "                y_train4[n] = y_train3[n]\n",
    "\n",
    "            n += 1  \n",
    "\n",
    "\n",
    "        #test\n",
    "        n = 0\n",
    "        for a, b, c in zip(mis_test_error_3, y_all_test, test_indexs[0]):                                \n",
    "            if a != 0:\n",
    "                #4 labels\n",
    "                if c in mis_test_1 and c in mis_test_2 and c in mis_test_3:\n",
    "                    if b[3] == b[0] and b[1] == b[2]:    \n",
    "                        y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    elif b[3] == b[1] and b[0] == b[2]:    \n",
    "                        y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    elif b[3] == b[2] and b[0] == b[1]:    \n",
    "                        y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    elif b[3] != b[0] and b[3] != b[1] and b[3] != b[2] and b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_test4[n] = int((b[3] + b[0] + b[1] + b[2])/4)\n",
    "                    else:\n",
    "                        y_test4[n] = statistics.mode([int(b[0]),int(b[3]),int(b[1]), int(b[2])])\n",
    "\n",
    "                # 3 labels\n",
    "                elif c in mis_test_1 and c in mis_test_3:\n",
    "                    if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_test4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                    else:\n",
    "                        y_test4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "\n",
    "\n",
    "                #3 labels\n",
    "                elif c in mis_test_2 and c in mis_test_3:\n",
    "                    if b[0] != b[1] and b[0] != b[2] and b[1] != b[2]:\n",
    "                        y_test4[n] = int((b[0] + b[1] + b[2])/3)\n",
    "                    else:\n",
    "                        y_test4[n] = statistics.mode([int(b[0]),int(b[1]),int(b[2])])\n",
    "\n",
    "                #2 labels\n",
    "                else:\n",
    "                    y_test4[n] = int((b[0] + b[1])/2)\n",
    "            else:\n",
    "                y_test4[n] = y_test3[n]\n",
    "\n",
    "            n += 1  \n",
    "\n",
    "        #Prediction\n",
    "        #Balanced\n",
    "        X_train_balanced, y_train4_balanced = sm.fit_sample(X_train, y_train4)\n",
    "        #predict synthetic IH\n",
    "        p = linreg.predict(X_train_balanced[X_train.shape[0]:])\n",
    "        p = np.exp(p*np.log(10))\n",
    "        IH_train_balanced = np.concatenate((IH_train, p), axis=0)\n",
    "        \n",
    "        y_train4_balanced = np.reshape(y_train4_balanced, (y_train4_balanced.shape[0], 1)).astype(int)\n",
    "        X_train_withlabels = np.concatenate((X_train_balanced, y_train4_balanced, IH_train_balanced), axis=1)\n",
    "\n",
    "        mis_train_4 = []\n",
    "        mis_test_4 = []\n",
    "\n",
    "        mixed_bags = create_mixed_bags(X_train_withlabels, IH_train_balanced.flatten(), \n",
    "                                       nbags, mix_ratio, hard_quotient)\n",
    "        clf = DecisionTreeClassifier(max_depth= 5)\n",
    "        train_pred = make_models(mixed_bags, clf, X_train)\n",
    "        test_pred = make_models(mixed_bags, clf, X_test)\n",
    "        bagging_train_pred= calculate_pred(train_pred)\n",
    "        bagging_test_pred= calculate_pred(test_pred)\n",
    "        \n",
    "        train_acc4.append(accuracy_score(y_train4, bagging_train_pred))\n",
    "        test_acc4.append(accuracy_score(y_test4, bagging_test_pred))\n",
    "\n",
    "        #train\n",
    "        cm = confusion_matrix(y_train4, bagging_train_pred, labels=[1, 2, 3, 4, 5])\n",
    "        train_acc_class = []\n",
    "        train_sen_class = []\n",
    "        train_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            train_acc_class.append(accuracy)\n",
    "            train_sen_class.append(sensitivity)\n",
    "            train_spe_class.append(specificity)\n",
    "\n",
    "        train_acc4_classes.append(train_acc_class)\n",
    "        train_sen4_classes.append(train_sen_class)\n",
    "        train_spe4_classes.append(train_spe_class)\n",
    "\n",
    "        #test\n",
    "        cm = confusion_matrix(y_test4, bagging_test_pred, labels=[1, 2, 3, 4, 5])\n",
    "        test_acc_class = []\n",
    "        test_sen_class = []\n",
    "        test_spe_class = []\n",
    "\n",
    "        for i in range(5):  \n",
    "            TP = cm[i][i]\n",
    "            FN = cm[i].sum() - TP\n",
    "            FP = cm.T[i].sum() - TP\n",
    "            TN = cm.sum() - TP - FN - FP\n",
    "            accuracy = (TP+TN)/cm.sum()\n",
    "            sensitivity = TP/(TP+FN)\n",
    "            specificity = TN/(TN+FP)\n",
    "\n",
    "            test_acc_class.append(accuracy)\n",
    "            test_sen_class.append(sensitivity)\n",
    "            test_spe_class.append(specificity)\n",
    "\n",
    "        test_acc4_classes.append(test_acc_class)\n",
    "        test_sen4_classes.append(test_sen_class)\n",
    "        test_spe4_classes.append(test_spe_class)  \n",
    "\n",
    "        #calculate errors\n",
    "        mis_train_error_4 = abs(y_train4 - bagging_train_pred)\n",
    "        mis_test_error_4 = abs(y_test4 - bagging_test_pred)\n",
    "\n",
    "        c = 0\n",
    "        for i, j in zip(mis_train_error_4, train_indexs[0]):\n",
    "            if j not in mis_train_1 and j not in mis_train_2 and j not in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_1[c] = i\n",
    "            elif j in mis_train_1 and j not in mis_train_2 and j not in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            elif j not in mis_train_1 and j in mis_train_2 and j not in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            elif j not in mis_train_1 and j not in mis_train_2 and j in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            elif j in mis_train_1 and j in mis_train_2 and j not in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            elif j not in mis_train_1 and j in mis_train_2 and j in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            elif j in mis_train_1 and j not in mis_train_2 and j in mis_train_3:\n",
    "                mis_train_error_4[c] = 0\n",
    "                mis_train_error_2[c] = i\n",
    "            c += 1\n",
    "\n",
    "        c = 0\n",
    "        for i, j in zip(mis_test_error_4, test_indexs[0]):\n",
    "            if j not in mis_test_1 and j not in mis_test_2 and j not in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_1[c] = i\n",
    "            elif j in mis_test_1 and j not in mis_test_2 and j not in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            elif j not in mis_test_1 and j in mis_test_2 and j not in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            elif j not in mis_test_1 and j not in mis_test_2 and j in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            elif j in mis_test_1 and j in mis_test_2 and j not in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            elif j not in mis_test_1 and j in mis_test_2 and j in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            elif j in mis_test_1 and j not in mis_test_2 and j in mis_test_3:\n",
    "                mis_test_error_4[c] = 0\n",
    "                mis_test_error_2[c] = i\n",
    "            c += 1\n",
    "\n",
    "        #track\n",
    "        #train\n",
    "        for i, j in zip(mis_train_error_4, train_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_train_4.append(j)\n",
    "\n",
    "        #test\n",
    "        for i, j in zip(mis_test_error_4, test_indexs[0]):\n",
    "            if i != 0:\n",
    "                mis_test_4.append(j)\n",
    "\n",
    "        cost4.append(len(mis_train_4)+len(mis_test_4))  \n",
    "\n",
    "        print(number)\n",
    "        number += 1\n",
    "\n",
    "    ave_acc1 = round(sum(test_acc1)/len(test_acc1),4)*100\n",
    "    ave_acc2 = round(sum(test_acc2)/len(test_acc2),4)*100\n",
    "    ave_acc3 = round(sum(test_acc3)/len(test_acc3),4)*100\n",
    "    ave_acc4 = round(sum(test_acc4)/len(test_acc4),4)*100\n",
    "\n",
    "    print(\"\\n\",\"testing accuracy\", ave_acc1, ave_acc2, ave_acc3, ave_acc4)\n",
    "    print(\"\\n\",\"all testing accuracies\", mean_confidence_interval(test_acc1), mean_confidence_interval(test_acc2), mean_confidence_interval(test_acc3), mean_confidence_interval(test_acc4))\n",
    "\n",
    "    #Iteration 1 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in train_sen1_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration1 train sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 2 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in train_sen2_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration2 train sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 3 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in train_sen3_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration3 train sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 4 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in train_sen4_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration4 train sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 1 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in test_sen1_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration1 test sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 2 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in test_sen2_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration2 test sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 3 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in test_sen3_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration3 test sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, \"class2\", round(sum(class2)/len(class2),4)*100,\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, \"class4\", round(sum(class4)/len(class4),4)*100, \"class5\", round(sum(class5)/len(class5),4)*100)\n",
    "\n",
    "    #Iteration 4 Sensitivity\n",
    "    class1 = []\n",
    "    class2 = []\n",
    "    class3 = []\n",
    "    class4 = []\n",
    "    class5 = []\n",
    "    for I in test_sen4_classes:\n",
    "        class1.append(I[0])\n",
    "        class2.append(I[1])\n",
    "        class3.append(I[2])\n",
    "        class4.append(I[3])\n",
    "        class5.append(I[4])\n",
    "\n",
    "    print(\"\\n\", \"Iteration4 test sensitivity\", \"class1\", round(sum(class1)/len(class1),4)*100, mean_confidence_interval(class1),\n",
    "          \"class2\", round(sum(class2)/len(class2),4)*100, mean_confidence_interval(class2),\n",
    "          \"class3\", round(sum(class3)/len(class3),4)*100, mean_confidence_interval(class3),\n",
    "          \"class4\", round(sum(class4)/len(class4),4)*100, mean_confidence_interval(class4),\n",
    "          \"class5\", round(sum(class5)/len(class5),4)*100, mean_confidence_interval(class5))\n",
    "    print(\"\\n\", \"all class 1\", class1)\n",
    "    print(\"\\n\", \"all class 2\", class2)\n",
    "    print(\"\\n\", \"all class 3\", class3)\n",
    "    print(\"\\n\", \"all class 4\", class4)\n",
    "    print(\"\\n\", \"all class 5\", class5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\n\", \"cost\", int(815 + sum(cost1)/len(cost1) + sum(cost2)/len(cost2) + sum(cost3)/len(cost3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
